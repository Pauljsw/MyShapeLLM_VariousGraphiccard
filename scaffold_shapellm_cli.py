#!/usr/bin/env python3
"""
ë¹„ê³„ ì•ˆì „ ê²€ì¦ íŠ¹í™” ShapeLLM CLI
ScaffoldPointLoRAê°€ í†µí•©ëœ ShapeLLMìœ¼ë¡œ ë¹„ê³„ ì•ˆì „ ë¶„ì„ ìˆ˜í–‰
"""

import argparse
import torch
import numpy as np
from pathlib import Path
import json
import time
from typing import Dict, Any

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ import
from integrate_scaffold_pointlora import (
    ScaffoldEnhancedCLIPVisionTower, 
    ScaffoldDataProcessor,
    create_scaffold_enhanced_shapellm,
    save_scaffold_lora_weights,
    load_scaffold_lora_weights
)


class ScaffoldSafetyAnalyzer:
    """
    ë¹„ê³„ ì•ˆì „ ë¶„ì„ê¸°
    ScaffoldPointLoRAê°€ ì ìš©ëœ ShapeLLMìœ¼ë¡œ ë¹„ê³„ êµ¬ì¡° ì•ˆì „ì„± ë¶„ì„
    """
    
    def __init__(self, model_path: str, lora_config: Dict[str, Any] = None):
        self.model_path = model_path
        self.lora_config = lora_config or {
            'use_scaffold_lora': True,
            'scaffold_lora_rank': 16,
            'scaffold_lora_alpha': 32.0,
            'training_stage': 'lora_only'
        }
        
        # ë°ì´í„° ì²˜ë¦¬ê¸°
        self.data_processor = ScaffoldDataProcessor()
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.model = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # ë¹„ê³„ ì•ˆì „ ê²€ì‚¬ í…œí”Œë¦¿
        self.safety_prompts = {
            'structural_analysis': """
            ì´ ë¹„ê³„ êµ¬ì¡°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:
            1. ì „ì²´ì ì¸ êµ¬ì¡°ì  ì•ˆì •ì„±ì€ ì–´ë–¤ê°€ìš”?
            2. ì§€ì§€ëŒ€ì™€ ì—°ê²°ë¶€ì˜ ìƒíƒœëŠ” ê´œì°®ë‚˜ìš”?
            3. ë°œê²¬ë˜ëŠ” ì•ˆì „ ìœ„í—˜ ìš”ì†Œê°€ ìˆë‚˜ìš”?
            4. ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ì„ êµ¬ì²´ì ìœ¼ë¡œ ì•Œë ¤ì£¼ì„¸ìš”.
            """,
            
            'working_platform_check': """
            ì‘ì—… í”Œë«í¼ì˜ ì•ˆì „ì„±ì„ ê²€ì‚¬í•´ì£¼ì„¸ìš”:
            1. í”Œë«í¼ í‘œë©´ì˜ ìƒíƒœëŠ” ì–´ë–¤ê°€ìš”?
            2. ì•ˆì „ë‚œê°„ì´ ì ì ˆíˆ ì„¤ì¹˜ë˜ì–´ ìˆë‚˜ìš”?
            3. ì¶œì…êµ¬ì™€ ì ‘ê·¼ ê²½ë¡œëŠ” ì•ˆì „í•œê°€ìš”?
            4. ì¶”ë½ ë°©ì§€ ì¡°ì¹˜ê°€ ì¶©ë¶„í•œê°€ìš”?
            """,
            
            'height_safety_assessment': """
            ë†’ì´ ì‘ì—… ì•ˆì „ì„±ì„ í‰ê°€í•´ì£¼ì„¸ìš”:
            1. ê° ë†’ì´ë³„ ì•ˆì „ ì¡°ì¹˜ëŠ” ì ì ˆí•œê°€ìš”?
            2. ìˆ˜ì§ ê°„ê²©ê³¼ ìˆ˜í‰ ê°„ê²©ì´ ê·œì •ì— ë§ë‚˜ìš”?
            3. ì‚¬ë‹¤ë¦¬ì™€ ì ‘ê·¼ ë°©ë²•ì´ ì•ˆì „í•œê°€ìš”?
            4. ë†’ì´ë³„ ìœ„í—˜ë„ í‰ê°€ ê²°ê³¼ëŠ” ì–´ë–¤ê°€ìš”?
            """,
            
            'comprehensive_report': """
            ì¢…í•©ì ì¸ ë¹„ê³„ ì•ˆì „ ì ê²€ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:
            1. ì „ì²´ ì•ˆì „ë„ ë“±ê¸‰ (A/B/C/D)
            2. ì£¼ìš” ë°œê²¬ ì‚¬í•­ (ìœ„í—˜ ìš”ì†Œ)
            3. ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš” í•­ëª©
            4. ê¶Œì¥ ê°œì„  ì‚¬í•­
            5. ì¬ê²€ì‚¬ ì£¼ê¸° ì œì•ˆ
            
            ë³´ê³ ì„œëŠ” í˜„ì¥ ì•ˆì „ ê´€ë¦¬ìê°€ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
            """
        }
    
    def load_model(self):
        """ScaffoldEnhanced ShapeLLM ë¡œë“œ"""
        print("ğŸ—ï¸ ScaffoldEnhanced ShapeLLM ë¡œë”© ì¤‘...")
        
        try:
            self.model = create_scaffold_enhanced_shapellm(
                model_path=self.model_path,
                **self.lora_config
            )
            
            if self.model:
                self.model = self.model.to(self.device)
                print(f"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ (Device: {self.device})")
                return True
            else:
                print("âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë”© ì˜¤ë¥˜: {e}")
            return False
    
    def analyze_scaffold(self, pts_file: str, analysis_type: str = 'comprehensive_report') -> Dict[str, Any]:
        """
        ë¹„ê³„ ì•ˆì „ ë¶„ì„ ìˆ˜í–‰
        
        Args:
            pts_file: ë¹„ê³„ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ íŒŒì¼ (.npy)
            analysis_type: ë¶„ì„ ìœ í˜• ('structural_analysis', 'working_platform_check', 
                          'height_safety_assessment', 'comprehensive_report')
        
        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if not self.model:
            print("âŒ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_model()ì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
            return None
        
        print(f"ğŸ” ë¹„ê³„ ì•ˆì „ ë¶„ì„ ì‹œì‘: {pts_file}")
        print(f"ğŸ“‹ ë¶„ì„ ìœ í˜•: {analysis_type}")
        
        start_time = time.time()
        
        try:
            # 1. ë°ì´í„° ì „ì²˜ë¦¬
            print("ğŸ“‚ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì²˜ë¦¬ ì¤‘...")
            processed_data = self.data_processor.process_scaffold_pointcloud(pts_file)
            
            if not processed_data:
                print("âŒ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨")
                return None
            
            print(f"âœ… ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: {processed_data['processed_shape']}")
            
            # 2. í…ì„œ ì¤€ë¹„
            points_tensor = torch.FloatTensor(processed_data['points']).unsqueeze(0).to(self.device)
            coords_tensor = torch.FloatTensor(processed_data['coordinates']).unsqueeze(0).to(self.device)
            
            # 3. ëª¨ë¸ ì¶”ë¡ 
            print("ğŸ§  ëª¨ë¸ ì¶”ë¡  ì¤‘...")
            with torch.no_grad():
                # ScaffoldPointLoRAì˜ multi-scale token selection ìˆ˜í–‰
                if hasattr(self.model, 'scaffold_lora'):
                    # ê¸°ë³¸ íŠ¹ì§• ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ReCon++ì—ì„œ ë‚˜ì˜´)
                    dummy_features = torch.randn(1, 8192, 768).to(self.device)
                    
                    selection_result = self.model.scaffold_lora(
                        dummy_features, coords_tensor, mode='token_selection'
                    )
                    
                    # ëª¨ë¸ forward pass
                    model_output = self.model(points_tensor)
                    
                    print(f"âœ… ëª¨ë¸ ì¶”ë¡  ì™„ë£Œ")
                    print(f"ğŸ¯ ì„ íƒëœ ì•ˆì „ ê´€ë ¨ í† í°: {selection_result['selected_tokens'].shape[1]}ê°œ")
                    print(f"ğŸ“Š í† í° ì„ íƒ ì •ë³´: {selection_result['selection_info']}")
            
            # 4. ì•ˆì „ ë¶„ì„ ê²°ê³¼ ìƒì„±
            analysis_result = self._generate_safety_analysis(
                processed_data, selection_result, analysis_type
            )
            
            end_time = time.time()
            analysis_result['processing_time'] = f"{end_time - start_time:.2f}ì´ˆ"
            
            print(f"ğŸ ë¶„ì„ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {analysis_result['processing_time']})")
            
            return analysis_result
            
        except Exception as e:
            print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return None
    
    def _generate_safety_analysis(self, processed_data: Dict, selection_result: Dict, 
                                analysis_type: str) -> Dict[str, Any]:
        """ì•ˆì „ ë¶„ì„ ê²°ê³¼ ìƒì„±"""
        
        # ë©”íƒ€ë°ì´í„°ì—ì„œ êµ¬ì¡° ì •ë³´ ì¶”ì¶œ
        metadata = processed_data['metadata']
        
        # í† í° ì„ íƒ ì •ë³´ì—ì„œ ì•ˆì „ íŠ¹ì§• ë¶„ì„
        selection_info = selection_result['selection_info']
        
        # ê¸°ë³¸ êµ¬ì¡° ë¶„ì„
        height_range = metadata['height_range']
        scaffold_height = height_range[1] - height_range[0]
        
        # ì•ˆì „ë„ í‰ê°€ (ì˜ˆì‹œ ë¡œì§)
        safety_score = self._calculate_safety_score(metadata, selection_info)
        
        # ë¶„ì„ ê²°ê³¼ êµ¬ì„±
        analysis = {
            'scaffold_info': {
                'file_path': processed_data.get('file_path', 'unknown'),
                'total_points': processed_data['processed_shape'][0],
                'scaffold_height': f"{scaffold_height:.2f}m",
                'dimensions': {
                    'width': f"{metadata['width_range'][1] - metadata['width_range'][0]:.2f}m",
                    'depth': f"{metadata['depth_range'][1] - metadata['depth_range'][0]:.2f}m",
                    'height': f"{scaffold_height:.2f}m"
                }
            },
            
            'pointlora_analysis': {
                'selected_safety_tokens': selection_info['total_selected'],
                'global_structure_tokens': selection_info['global_count'],
                'component_level_tokens': selection_info['component_count'],
                'detail_safety_tokens': selection_info['detail_count']
            },
            
            'safety_assessment': {
                'overall_safety_grade': self._get_safety_grade(safety_score),
                'safety_score': f"{safety_score:.1f}/100",
                'structural_integrity': self._assess_structural_integrity(metadata),
                'working_platform_safety': self._assess_platform_safety(metadata),
                'height_safety_compliance': self._assess_height_safety(metadata)
            },
            
            'recommendations': self._generate_recommendations(safety_score, metadata),
            
            'analysis_type': analysis_type,
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }
        
        return analysis
    
    def _calculate_safety_score(self, metadata: Dict, selection_info: Dict) -> float:
        """ì•ˆì „ ì ìˆ˜ ê³„ì‚° (0-100)"""
        
        # êµ¬ì¡°ì  ì•ˆì •ì„± ì ìˆ˜ (40ì )
        structural_score = min(40, metadata.get('vertical_structure_strength', 0) * 20)
        
        # í”Œë«í¼ ì•ˆì „ì„± ì ìˆ˜ (30ì )  
        platform_score = min(30, (1.0 / (metadata.get('horizontal_structure_strength', 1) + 0.1)) * 15)
        
        # PointLoRA í† í° ì„ íƒ í’ˆì§ˆ ì ìˆ˜ (30ì )
        token_quality = (selection_info['detail_count'] / 8) * 30  # detail í† í°ì´ ë§ì„ìˆ˜ë¡ ì¢‹ìŒ
        
        total_score = structural_score + platform_score + token_quality
        return min(100, max(0, total_score))
    
    def _get_safety_grade(self, score: float) -> str:
        """ì•ˆì „ ë“±ê¸‰ ë°˜í™˜"""
        if score >= 90:
            return "A (ìš°ìˆ˜)"
        elif score >= 80:
            return "B (ì–‘í˜¸)"
        elif score >= 70:
            return "C (ë³´í†µ)"
        elif score >= 60:
            return "D (ì£¼ì˜)"
        else:
            return "F (ìœ„í—˜)"
    
    def _assess_structural_integrity(self, metadata: Dict) -> str:
        """êµ¬ì¡°ì  ë¬´ê²°ì„± í‰ê°€"""
        strength = metadata.get('vertical_structure_strength', 0)
        
        if strength > 2.0:
            return "ì–‘í˜¸ - ìˆ˜ì§ êµ¬ì¡°ê°€ ì•ˆì •ì ì„"
        elif strength > 1.0:
            return "ë³´í†µ - ì¼ë¶€ ë³´ê°• ê²€í†  í•„ìš”"
        else:
            return "ì£¼ì˜ - êµ¬ì¡° ì•ˆì •ì„± ì ê²€ í•„ìš”"
    
    def _assess_platform_safety(self, metadata: Dict) -> str:
        """ì‘ì—… í”Œë«í¼ ì•ˆì „ì„± í‰ê°€"""
        variance = metadata.get('horizontal_structure_strength', 0)
        
        if variance < 0.5:
            return "ì–‘í˜¸ - ì‘ì—…ë©´ì´ í‰í‰í•˜ê³  ì•ˆì •ì ì„"
        elif variance < 1.0:
            return "ë³´í†µ - ì¼ë¶€ í‰íƒ„í™” ì‘ì—… í•„ìš”"
        else:
            return "ì£¼ì˜ - ì‘ì—…ë©´ ì•ˆì „ì„± ì ê²€ í•„ìš”"
    
    def _assess_height_safety(self, metadata: Dict) -> str:
        """ë†’ì´ ì•ˆì „ì„± í‰ê°€"""
        height_density = metadata.get('height_density', [])
        
        if len(height_density) > 0:
            # ê· ë“±í•œ ë¶„í¬ì¼ìˆ˜ë¡ ì•ˆì „ (ê³„ë‹¨ì‹ êµ¬ì¡°)
            density_variance = np.var(height_density)
            
            if density_variance < 100:
                return "ì–‘í˜¸ - ë†’ì´ë³„ êµ¬ì¡°ê°€ ê· ë“±í•¨"
            elif density_variance < 200:
                return "ë³´í†µ - ì¼ë¶€ ì¸µ ë³´ê°• ê²€í† "
            else:
                return "ì£¼ì˜ - ë†’ì´ë³„ ì•ˆì „ ì¡°ì¹˜ ì ê²€ í•„ìš”"
        else:
            return "ì •ë³´ ë¶€ì¡± - ì¶”ê°€ ë¶„ì„ í•„ìš”"
    
    def _generate_recommendations(self, safety_score: float, metadata: Dict) -> list:
        """ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if safety_score < 70:
            recommendations.append("ğŸš¨ ì¦‰ì‹œ ì¡°ì¹˜: ì „ë¬¸ê°€ ì•ˆì „ ì ê²€ ì‹¤ì‹œ")
        
        if metadata.get('vertical_structure_strength', 0) < 1.5:
            recommendations.append("ğŸ”§ êµ¬ì¡° ë³´ê°•: ìˆ˜ì§ ì§€ì§€ëŒ€ ë° ì—°ê²°ë¶€ ì ê²€ í•„ìš”")
        
        if metadata.get('horizontal_structure_strength', 0) > 1.0:
            recommendations.append("ğŸ“ ì‘ì—…ë©´ ì •ë¹„: í”Œë«í¼ í‰íƒ„ë„ ê°œì„  í•„ìš”")
        
        height_range = metadata.get('height_range', [0, 0])
        if height_range[1] - height_range[0] > 10:  # 10m ì´ìƒ
            recommendations.append("ğŸ›¡ï¸ ë†’ì´ ì•ˆì „: ì¶”ê°€ ì•ˆì „ë‚œê°„ ë° ì¶”ë½ë°©ì§€ ì¡°ì¹˜ í•„ìš”")
        
        if safety_score >= 80:
            recommendations.append("âœ… í˜„ì¬ ìƒíƒœ ì–‘í˜¸: ì •ê¸° ì ê²€ ì£¼ê¸° ìœ ì§€")
        
        recommendations.append("ğŸ“‹ ë‹¤ìŒ ì ê²€ì¼: 1ê°œì›” í›„ ì¬ê²€ì‚¬ ê¶Œì¥")
        
        return recommendations


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ë¹„ê³„ ì•ˆì „ ê²€ì¦ íŠ¹í™” ShapeLLM CLI')
    
    # í•„ìˆ˜ ì¸ì
    parser.add_argument('--pts-file', type=str, required=True,
                       help='ë¹„ê³„ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ íŒŒì¼ ê²½ë¡œ (.npy)')
    
    # ì„ íƒì  ì¸ì
    parser.add_argument('--model-path', type=str, 
                       default='qizekun/ShapeLLM_13B_general_v1.0',
                       help='ShapeLLM ëª¨ë¸ ê²½ë¡œ')
    
    parser.add_argument('--analysis-type', type=str,
                       choices=['structural_analysis', 'working_platform_check', 
                               'height_safety_assessment', 'comprehensive_report'],
                       default='comprehensive_report',
                       help='ë¶„ì„ ìœ í˜• ì„ íƒ')
    
    parser.add_argument('--lora-rank', type=int, default=16,
                       help='LoRA rank (ê¸°ë³¸ê°’: 16)')
    
    parser.add_argument('--lora-alpha', type=float, default=32.0,
                       help='LoRA alpha (ê¸°ë³¸ê°’: 32.0)')
    
    parser.add_argument('--training-stage', type=str,
                       choices=['lora_only', 'full'], default='lora_only',
                       help='í›ˆë ¨ ë‹¨ê³„ (ê¸°ë³¸ê°’: lora_only)')
    
    parser.add_argument('--save-lora', type=str, default=None,
                       help='LoRA ê°€ì¤‘ì¹˜ ì €ì¥ ê²½ë¡œ (ì„ íƒì‚¬í•­)')
    
    parser.add_argument('--load-lora', type=str, default=None,
                       help='ì €ì¥ëœ LoRA ê°€ì¤‘ì¹˜ ë¡œë“œ ê²½ë¡œ (ì„ íƒì‚¬í•­)')
    
    parser.add_argument('--output', type=str, default=None,
                       help='ë¶„ì„ ê²°ê³¼ ì €ì¥ íŒŒì¼ (JSON í˜•ì‹)')
    
    parser.add_argument('--verbose', action='store_true',
                       help='ìƒì„¸ ë¡œê·¸ ì¶œë ¥')
    
    args = parser.parse_args()
    
    # ë¡œê¹… ì„¤ì •
    if args.verbose:
        import logging
        logging.basicConfig(level=logging.DEBUG)
    
    # ì…ë ¥ íŒŒì¼ í™•ì¸
    if not Path(args.pts_file).exists():
        print(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {args.pts_file}")
        return
    
    print("ğŸ—ï¸ ScaffoldPointLoRA ë¹„ê³„ ì•ˆì „ ë¶„ì„ ì‹œì‘")
    print(f"ğŸ“‚ ì…ë ¥ íŒŒì¼: {args.pts_file}")
    print(f"ğŸ§  ëª¨ë¸: {args.model_path}")
    print(f"ğŸ“‹ ë¶„ì„ ìœ í˜•: {args.analysis_type}")
    print("=" * 50)
    
    # LoRA ì„¤ì •
    lora_config = {
        'use_scaffold_lora': True,
        'scaffold_lora_rank': args.lora_rank,
        'scaffold_lora_alpha': args.lora_alpha,
        'training_stage': args.training_stage
    }
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = ScaffoldSafetyAnalyzer(args.model_path, lora_config)
    
    # ëª¨ë¸ ë¡œë“œ
    if not analyzer.load_model():
        print("âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
        return
    
    # ì €ì¥ëœ LoRA ê°€ì¤‘ì¹˜ ë¡œë“œ (ì˜µì…˜)
    if args.load_lora:
        if load_scaffold_lora_weights(analyzer.model, args.load_lora):
            print(f"âœ… LoRA ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ: {args.load_lora}")
        else:
            print(f"âš ï¸ LoRA ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨: {args.load_lora}")
    
    # ë¹„ê³„ ì•ˆì „ ë¶„ì„ ìˆ˜í–‰
    result = analyzer.analyze_scaffold(args.pts_file, args.analysis_type)
    
    if result:
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 50)
        print("ğŸ“Š ë¹„ê³„ ì•ˆì „ ë¶„ì„ ê²°ê³¼")
        print("=" * 50)
        
        # ê¸°ë³¸ ì •ë³´
        scaffold_info = result['scaffold_info']
        print(f"\nğŸ—ï¸ ë¹„ê³„ ì •ë³´:")
        print(f"   - ë†’ì´: {scaffold_info['scaffold_height']}")
        print(f"   - í¬ê¸°: {scaffold_info['dimensions']['width']} Ã— {scaffold_info['dimensions']['depth']}")
        print(f"   - í¬ì¸íŠ¸ ìˆ˜: {scaffold_info['total_points']:,}ê°œ")
        
        # PointLoRA ë¶„ì„ ê²°ê³¼
        pointlora_result = result['pointlora_analysis']
        print(f"\nğŸ¯ PointLoRA ì•ˆì „ íŠ¹ì§• ë¶„ì„:")
        print(f"   - ì„ íƒëœ ì•ˆì „ í† í°: {pointlora_result['selected_safety_tokens']}ê°œ")
        print(f"   - ì „ì²´ êµ¬ì¡° í† í°: {pointlora_result['global_structure_tokens']}ê°œ")
        print(f"   - êµ¬ì„±ìš”ì†Œ í† í°: {pointlora_result['component_level_tokens']}ê°œ")
        print(f"   - ì„¸ë¶€ ì•ˆì „ í† í°: {pointlora_result['detail_safety_tokens']}ê°œ")
        
        # ì•ˆì „ì„± í‰ê°€
        safety_assessment = result['safety_assessment']
        print(f"\nğŸ›¡ï¸ ì•ˆì „ì„± í‰ê°€:")
        print(f"   - ì¢…í•© ì•ˆì „ ë“±ê¸‰: {safety_assessment['overall_safety_grade']}")
        print(f"   - ì•ˆì „ ì ìˆ˜: {safety_assessment['safety_score']}")
        print(f"   - êµ¬ì¡°ì  ë¬´ê²°ì„±: {safety_assessment['structural_integrity']}")
        print(f"   - ì‘ì—… í”Œë«í¼: {safety_assessment['working_platform_safety']}")
        print(f"   - ë†’ì´ ì•ˆì „ì„±: {safety_assessment['height_safety_compliance']}")
        
        # ê¶Œì¥ì‚¬í•­
        print(f"\nğŸ“‹ ê¶Œì¥ì‚¬í•­:")
        for i, rec in enumerate(result['recommendations'], 1):
            print(f"   {i}. {rec}")
        
        print(f"\nâ±ï¸ ì²˜ë¦¬ ì‹œê°„: {result['processing_time']}")
        
        # ê²°ê³¼ íŒŒì¼ ì €ì¥ (ì˜µì…˜)
        if args.output:
            try:
                with open(args.output, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥: {args.output}")
            except Exception as e:
                print(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # LoRA ê°€ì¤‘ì¹˜ ì €ì¥ (ì˜µì…˜)
        if args.save_lora:
            save_scaffold_lora_weights(analyzer.model, args.save_lora)
        
    else:
        print("âŒ ë¶„ì„ ì‹¤íŒ¨")


def interactive_mode():
    """ëŒ€í™”í˜• ëª¨ë“œ"""
    print("ğŸ—ï¸ ScaffoldPointLoRA ëŒ€í™”í˜• ëª¨ë“œ")
    print("ë¹„ê³„ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ íŒŒì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤.")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n")
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™” (ê¸°ë³¸ ì„¤ì •)
    analyzer = ScaffoldSafetyAnalyzer(
        model_path="qizekun/ShapeLLM_13B_general_v1.0",
        lora_config={
            'use_scaffold_lora': True,
            'scaffold_lora_rank': 16,
            'scaffold_lora_alpha': 32.0,
            'training_stage': 'lora_only'
        }
    )
    
    # ëª¨ë¸ ë¡œë“œ
    if not analyzer.load_model():
        print("âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
        return
    
    while True:
        try:
            # íŒŒì¼ ê²½ë¡œ ì…ë ¥
            pts_file = input("\nğŸ“‚ ë¹„ê³„ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ íŒŒì¼ ê²½ë¡œ (.npy): ").strip()
            
            if pts_file.lower() in ['quit', 'exit']:
                print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            if not pts_file:
                continue
                
            if not Path(pts_file).exists():
                print(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {pts_file}")
                continue
            
            # ë¶„ì„ ìœ í˜• ì„ íƒ
            print("\nğŸ“‹ ë¶„ì„ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”:")
            print("1. êµ¬ì¡° ë¶„ì„ (structural_analysis)")
            print("2. ì‘ì—… í”Œë«í¼ ê²€ì‚¬ (working_platform_check)")
            print("3. ë†’ì´ ì•ˆì „ì„± í‰ê°€ (height_safety_assessment)")
            print("4. ì¢…í•© ë³´ê³ ì„œ (comprehensive_report) [ê¸°ë³¸ê°’]")
            
            choice = input("ì„ íƒ (1-4, ê¸°ë³¸ê°’: 4): ").strip()
            
            analysis_types = {
                '1': 'structural_analysis',
                '2': 'working_platform_check', 
                '3': 'height_safety_assessment',
                '4': 'comprehensive_report'
            }
            
            analysis_type = analysis_types.get(choice, 'comprehensive_report')
            
            # ë¶„ì„ ìˆ˜í–‰
            print(f"\nğŸ” ë¶„ì„ ì‹œì‘... ({analysis_type})")
            result = analyzer.analyze_scaffold(pts_file, analysis_type)
            
            if result:
                # ê°„ë‹¨í•œ ê²°ê³¼ ì¶œë ¥
                safety_assessment = result['safety_assessment']
                print(f"\nâœ… ë¶„ì„ ì™„ë£Œ!")
                print(f"ğŸ›¡ï¸ ì•ˆì „ ë“±ê¸‰: {safety_assessment['overall_safety_grade']}")
                print(f"ğŸ“Š ì•ˆì „ ì ìˆ˜: {safety_assessment['safety_score']}")
                
                # ìƒì„¸ ê²°ê³¼ ì¶œë ¥ ì—¬ë¶€
                detail = input("\nìƒì„¸ ê²°ê³¼ë¥¼ ë³´ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
                if detail in ['y', 'yes']:
                    print("\n" + "=" * 50)
                    print("ğŸ“‹ ìƒì„¸ ë¶„ì„ ê²°ê³¼")
                    print("=" * 50)
                    
                    for i, rec in enumerate(result['recommendations'], 1):
                        print(f"{i}. {rec}")
                
                # ê²°ê³¼ ì €ì¥ ì—¬ë¶€  
                save = input("\nê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
                if save in ['y', 'yes']:
                    output_file = input("ì €ì¥í•  íŒŒì¼ëª… (ê¸°ë³¸ê°’: scaffold_analysis.json): ").strip()
                    if not output_file:
                        output_file = "scaffold_analysis.json"
                    
                    try:
                        with open(output_file, 'w', encoding='utf-8') as f:
                            json.dump(result, f, ensure_ascii=False, indent=2)
                        print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_file}")
                    except Exception as e:
                        print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
            else:
                print("âŒ ë¶„ì„ ì‹¤íŒ¨")
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) == 1:
        # ì¸ìê°€ ì—†ìœ¼ë©´ ëŒ€í™”í˜• ëª¨ë“œ ì‹¤í–‰
        interactive_mode()
    else:
        # ì¸ìê°€ ìˆìœ¼ë©´ CLI ëª¨ë“œ ì‹¤í–‰
        main()
