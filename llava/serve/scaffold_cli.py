#!/usr/bin/env python3
"""
ShapeLLM/llava/serve/scaffold_cli.py

ë¹„ê³„ ì•ˆì „ ê²€ì¦ íŠ¹í™” ShapeLLM CLI
- ScaffoldPointLoRA í†µí•©
- ê¸°ì¡´ ShapeLLM conversation ì‹œìŠ¤í…œ í™œìš©
- ë¹„ê³„ ì•ˆì „ ì „ë¬¸ ë¶„ì„ ì œê³µ
"""

import torch
import argparse
import numpy as np
import json
import time
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional

# ShapeLLM ê¸°ì¡´ ëª¨ë“ˆë“¤
from transformers import TextStreamer
from llava.utils import disable_torch_init
from llava.model.builder import load_pretrained_model
from llava.conversation import conv_templates, SeparatorStyle, Conversation
from llava.constants import POINT_TOKEN_INDEX, DEFAULT_POINT_TOKEN, DEFAULT_PT_START_TOKEN, DEFAULT_PT_END_TOKEN
from llava.mm_utils import load_pts, process_pts, rotation, tokenizer_point_token, get_model_name_from_path, KeywordsStoppingCriteria

# ScaffoldPointLoRA ëª¨ë“ˆë“¤ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ import)
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))  # ShapeLLM ë£¨íŠ¸ë¡œ ì´ë™

from ScaffoldPointLoRA import ScaffoldPointLoRA, ScaffoldTokenSelector, ScaffoldLoRALayer
from integrate_scaffold_pointlora import ScaffoldEnhancedCLIPVisionTower, ScaffoldDataProcessor


class ScaffoldSafetyCLI:
    """
    ë¹„ê³„ ì•ˆì „ ê²€ì¦ íŠ¹í™” CLI í´ë˜ìŠ¤
    ê¸°ì¡´ ShapeLLM + ScaffoldPointLoRA í†µí•©
    """
    
    def __init__(self, args):
        self.args = args
        self.model = None
        self.tokenizer = None
        self.context_len = None
        self.conv = None
        self.scaffold_lora = None
        self.data_processor = ScaffoldDataProcessor()
        
        # ë¹„ê³„ ì•ˆì „ conversation template ë“±ë¡
        self._register_scaffold_conversation()
        
        # ë¹„ê³„ ì•ˆì „ ì „ë¬¸ í”„ë¡¬í”„íŠ¸ë“¤
        self.safety_prompts = {
            'comprehensive': """
ì´ ë¹„ê³„ êµ¬ì¡°ì˜ ì¢…í•©ì ì¸ ì•ˆì „ì„±ì„ í‰ê°€í•´ì£¼ì„¸ìš”:

1. **êµ¬ì¡°ì  ì•ˆì •ì„±**: ì§€ì§€ëŒ€, ì—°ê²°ë¶€, ì „ì²´ì  í”„ë ˆì„ì›Œí¬ì˜ ê²¬ê³ ì„±
2. **ì‘ì—… í”Œë«í¼**: í”Œë«í¼ í‘œë©´, ì•ˆì „ë‚œê°„, ì¶œì…êµ¬ì˜ ì•ˆì „ì„±  
3. **ë†’ì´ ì•ˆì „**: ê° ì¸µë³„ ì•ˆì „ ì¡°ì¹˜, ì¶”ë½ ë°©ì§€ ëŒ€ì±…
4. **ì¢…í•© í‰ê°€**: ì•ˆì „ ë“±ê¸‰(A/B/C/D)ê³¼ êµ¬ì²´ì  ê°œì„  ê¶Œì¥ì‚¬í•­

ì •ëŸ‰ì  ë¶„ì„ê³¼ ì‹¤ìš©ì  ê¶Œì¥ì‚¬í•­ì„ í¬í•¨í•´ í˜„ì¥ì—ì„œ ë°”ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” ë³´ê³ ì„œ í˜•íƒœë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
            """,
            
            'structural': """
ì´ ë¹„ê³„ì˜ êµ¬ì¡°ì  ì•ˆì •ì„±ì„ ì¤‘ì  ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ì£¼ìš” ì§€ì§€ì **: ê¸°ë‘¥ê³¼ ìˆ˜ì§ êµ¬ì¡°ë¬¼ì˜ ìƒíƒœ
2. **ì—°ê²°ë¶€ ë¬´ê²°ì„±**: ì¡°ì¸íŠ¸, ë³¼íŠ¸, í´ë¨í”„ì˜ ê²¬ê³ ì„±
3. **í•˜ì¤‘ ë¶„ì‚°**: ì¤‘ëŸ‰ ë¶„ë°°ì™€ êµ¬ì¡°ì  ê· í˜•
4. **ë³€í˜• ë° ì†ìƒ**: íœ˜ì–´ì§, ê· ì—´, ë¶€ì‹ ë“±ì˜ êµ¬ì¡°ì  ê²°í•¨

êµ¬ì¡° ì—”ì§€ë‹ˆì–´ë§ ê´€ì ì—ì„œ ìƒì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”.
            """,
            
            'platform': """
ì‘ì—… í”Œë«í¼ì˜ ì•ˆì „ì„±ì„ ê²€ì‚¬í•´ì£¼ì„¸ìš”:

1. **í”Œë«í¼ í‘œë©´**: í‰íƒ„ë„, ë¯¸ë„ëŸ¼ ë°©ì§€, ë°°ìˆ˜ ìƒíƒœ
2. **ì•ˆì „ë‚œê°„**: ë†’ì´, ê²¬ê³ ì„±, ì—°ì†ì„± ê²€ì‚¬
3. **ì ‘ê·¼ ê²½ë¡œ**: ì‚¬ë‹¤ë¦¬, ì¶œì…êµ¬, í†µí–‰ë¡œì˜ ì•ˆì „ì„±
4. **ì‘ì—… ê³µê°„**: ì¶©ë¶„í•œ ì‘ì—… ì—¬ìœ ê³µê°„ í™•ë³´

ì‘ì—…ì ì•ˆì „ ì¤‘ì‹¬ìœ¼ë¡œ ì‹¤ë¬´ì§„ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
            """,
            
            'height_safety': """
ë†’ì´ ì‘ì—… ì•ˆì „ì„±ì„ í‰ê°€í•´ì£¼ì„¸ìš”:

1. **ì¸µë³„ ì•ˆì „ ì¡°ì¹˜**: ê° ë†’ì´ì—ì„œì˜ ì¶”ë½ ë°©ì§€ ëŒ€ì±…
2. **ìˆ˜ì§/ìˆ˜í‰ ê°„ê²©**: ì•ˆì „ ê¸°ì¤€ì— ë§ëŠ” ê°„ê²© ìœ ì§€
3. **ì ‘ê·¼ ë°©ë²•**: ì‚¬ë‹¤ë¦¬, ê³„ë‹¨ì˜ ì•ˆì „ì„±ê³¼ ê°ë„
4. **ë¹„ìƒ ëŒ€ì‘**: ì‘ê¸‰ìƒí™© ì‹œ ëŒ€í”¼ ê²½ë¡œì™€ êµ¬ì¡° ë°©ë²•

ê³ ì†Œ ì‘ì—… ì „ë¬¸ê°€ ê´€ì ì—ì„œ ìœ„í—˜ë„ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”.
            """
        }
    
    def _register_scaffold_conversation(self):
        """ë¹„ê³„ ì•ˆì „ íŠ¹í™” conversation template ë“±ë¡"""
        
        conv_scaffold_safety = Conversation(
            system="""ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ë¹„ê³„ ì•ˆì „ ê²€ì‚¬ AIì…ë‹ˆë‹¤.

3D í¬ì¸íŠ¸ í´ë¼ìš°ë“œë¡œ ì œê³µë˜ëŠ” ë¹„ê³„ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ ì•ˆì „ì„±ì„ í‰ê°€í•˜ê³ , ê±´ì„¤ ì•ˆì „ ê·œì •ì— ë”°ë¥¸ ê²€ì‚¬ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

**ì „ë¬¸ ë¶„ì•¼:**
- êµ¬ì¡°ì  ì•ˆì •ì„± (ì§€ì§€ëŒ€, ì—°ê²°ë¶€, í”„ë ˆì„ì›Œí¬)
- ì‘ì—… í”Œë«í¼ ì•ˆì „ì„± (í‘œë©´, ë‚œê°„, ì ‘ê·¼ë¡œ)  
- ë†’ì´ ì‘ì—… ì•ˆì „ì„± (ì¶”ë½ ë°©ì§€, ì¸µë³„ ì¡°ì¹˜)
- ì•ˆì „ ê·œì • ì¤€ìˆ˜ì„± (ê´€ë ¨ ë²•ê·œ ë° ê¸°ì¤€)

**ë¶„ì„ ë°©ì‹:**
- ì •ëŸ‰ì  ì¸¡ì •ê°’ê³¼ ì •ì„±ì  í‰ê°€ ê²°í•©
- ì¦‰ì‹œ ì¡°ì¹˜ ì‚¬í•­ê³¼ ê¶Œì¥ ê°œì„  ì‚¬í•­ êµ¬ë¶„
- í˜„ì¥ ì‹¤ë¬´ì§„ì´ ë°”ë¡œ ì ìš© ê°€ëŠ¥í•œ êµ¬ì²´ì  ì§€ì¹¨ ì œê³µ
- ì•ˆì „ ë“±ê¸‰(A/B/C/D) ë¶€ì—¬ì™€ ê·¼ê±° ëª…ì‹œ

ì „ë¬¸ì ì´ë©´ì„œë„ í˜„ì¥ì—ì„œ ì‹¤ìš©ì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”.""",
            roles=("INSPECTOR", "SAFETY_AI"),
            version="scaffold_v1",
            messages=(),
            offset=0,
            sep_style=SeparatorStyle.TWO,
            sep=" ",
            sep2="</s>",
        )
        
        # conversation templateì— ë“±ë¡
        conv_templates["scaffold_safety"] = conv_scaffold_safety
    
    def load_model(self):
        """ëª¨ë¸ ë¡œë”© ë° ScaffoldPointLoRA ì ìš©"""
        print("ğŸ—ï¸ ScaffoldPointLoRA Enhanced ShapeLLM ë¡œë”© ì¤‘...")
        
        disable_torch_init()
        
        # ê¸°ë³¸ ShapeLLM ëª¨ë¸ ë¡œë“œ
        model_name = get_model_name_from_path(self.args.model_path)
        self.tokenizer, self.model, self.context_len = load_pretrained_model(
            self.args.model_path, self.args.model_base, model_name, 
            self.args.load_8bit, self.args.load_4bit, device=self.args.device
        )
        
        # ScaffoldPointLoRA ì ìš©
        if self.args.use_scaffold_lora:
            print("ğŸ¯ ScaffoldPointLoRA ì ìš© ì¤‘...")
            self._apply_scaffold_lora()
        
        # Conversation ì„¤ì •
        conv_mode = "scaffold_safety"
        if self.args.conv_mode is not None and conv_mode != self.args.conv_mode:
            print(f'[WARNING] auto inferred conv mode is {conv_mode}, using {self.args.conv_mode}')
        else:
            self.args.conv_mode = conv_mode
        
        self.conv = conv_templates[self.args.conv_mode].copy()
        print(f"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ (Conv mode: {self.args.conv_mode})")
    
    def _apply_scaffold_lora(self):
        """ScaffoldPointLoRAë¥¼ ê¸°ì¡´ ëª¨ë¸ì— ì ìš©"""
        try:
            # Vision towerê°€ ìˆëŠ”ì§€ í™•ì¸
            if hasattr(self.model, 'get_vision_tower'):
                vision_tower = self.model.get_vision_tower()
                
                if vision_tower is not None:
                    # ScaffoldPointLoRA ì´ˆê¸°í™”
                    hidden_size = getattr(vision_tower.config, 'hidden_size', 768)
                    
                    self.scaffold_lora = ScaffoldPointLoRA(
                        hidden_size=hidden_size,
                        lora_rank=self.args.scaffold_lora_rank,
                        lora_alpha=self.args.scaffold_lora_alpha,
                        num_selected_tokens=40
                    )
                    
                    # GPUë¡œ ì´ë™
                    device = next(self.model.parameters()).device
                    self.scaffold_lora = self.scaffold_lora.to(device)
                    
                    # Vision towerì— LoRA í†µí•© (ê°„ë‹¨í•œ ë˜í•‘)
                    self._wrap_vision_tower_with_lora(vision_tower)
                    
                    # ë§¤ê°œë³€ìˆ˜ ê³ ì • ì„¤ì •
                    if self.args.training_stage == 'lora_only':
                        self._freeze_non_lora_parameters()
                    
                    # ë§¤ê°œë³€ìˆ˜ í†µê³„ ì¶œë ¥
                    self._print_parameter_stats()
                    
                    print("âœ… ScaffoldPointLoRA ì ìš© ì™„ë£Œ")
                else:
                    print("âš ï¸ Vision towerë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ, LoRA ì ìš© ê±´ë„ˆëœ€")
            else:
                print("âš ï¸ get_vision_tower ë©”ì„œë“œ ì—†ìŒ, LoRA ì ìš© ê±´ë„ˆëœ€")
                
        except Exception as e:
            print(f"âŒ ScaffoldPointLoRA ì ìš© ì‹¤íŒ¨: {e}")
            print("ê¸°ë³¸ ShapeLLMìœ¼ë¡œ ê³„ì† ì§„í–‰...")
    
    def _wrap_vision_tower_with_lora(self, vision_tower):
        """Vision towerì˜ forward í•¨ìˆ˜ë¥¼ LoRAë¡œ ë˜í•‘"""
        
        original_forward = vision_tower.forward
        
        def lora_enhanced_forward(pts):
            # ì›ë³¸ forward ì‹¤í–‰
            original_output = original_forward(pts)
            
            # ScaffoldPointLoRA ì ìš©
            if self.scaffold_lora is not None:
                try:
                    # í¬ì¸íŠ¸ ì¢Œí‘œ ì¶”ì¶œ
                    if isinstance(pts, list) and len(pts) > 0:
                        coords = pts[0][:, :3].unsqueeze(0)  # [1, N, 3]
                    elif isinstance(pts, torch.Tensor):
                        coords = pts[:, :, :3]  # [B, N, 3]
                    else:
                        return original_output
                    
                    # ê¸°ë³¸ íŠ¹ì§• ìƒì„± (ì‹¤ì œë¡œëŠ” ReCon++ì—ì„œ ë‚˜ì˜´)
                    batch_size, num_points = coords.shape[:2]
                    dummy_features = torch.randn(
                        batch_size, num_points, self.scaffold_lora.hidden_size, 
                        device=coords.device, dtype=coords.dtype
                    )
                    
                    # Multi-scale token selection ìˆ˜í–‰
                    selection_result = self.scaffold_lora(
                        dummy_features, coords, mode='token_selection'
                    )
                    
                    # ì„ íƒ ì •ë³´ ì €ì¥ (ë‚˜ì¤‘ì— ì¶œë ¥ìš©)
                    self._last_selection_info = selection_result['selection_info']
                    
                    print(f"ğŸ¯ ScaffoldPointLoRA í† í° ì„ íƒ: {selection_result['selected_tokens'].shape[1]}ê°œ")
                    
                except Exception as e:
                    print(f"âš ï¸ LoRA forward ì˜¤ë¥˜ (ì›ë³¸ ê²°ê³¼ ì‚¬ìš©): {e}")
            
            return original_output
        
        # Forward í•¨ìˆ˜ êµì²´
        vision_tower.forward = lora_enhanced_forward
    
    def _freeze_non_lora_parameters(self):
        """LoRAê°€ ì•„ë‹Œ ë§¤ê°œë³€ìˆ˜ë“¤ ê³ ì •"""
        for param in self.model.parameters():
            param.requires_grad = False
        
        if self.scaffold_lora is not None:
            for param in self.scaffold_lora.get_trainable_parameters():
                param.requires_grad = True
    
    def _print_parameter_stats(self):
        """ë§¤ê°œë³€ìˆ˜ í†µê³„ ì¶œë ¥"""
        if self.scaffold_lora is not None:
            total_params = sum(p.numel() for p in self.model.parameters())
            trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
            lora_params = sum(p.numel() for p in self.scaffold_lora.get_trainable_parameters())
            
            print("=" * 50)
            print("ğŸ“Š ë§¤ê°œë³€ìˆ˜ í†µê³„")
            print("=" * 50)
            print(f"ì „ì²´ ëª¨ë¸ ë§¤ê°œë³€ìˆ˜: {total_params:,}")
            print(f"í›ˆë ¨ ê°€ëŠ¥ ë§¤ê°œë³€ìˆ˜: {trainable_params:,}")
            print(f"LoRA ë§¤ê°œë³€ìˆ˜: {lora_params:,}")
            print(f"í›ˆë ¨ íš¨ìœ¨ì„±: {trainable_params/total_params:.2%}")
            print(f"ë©”ëª¨ë¦¬ ì ˆì•½: {1-(trainable_params/total_params):.2%}")
            print("=" * 50)
    
    def process_point_cloud(self, pts_file: str) -> Tuple[torch.Tensor, Dict]:
        """í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì „ì²˜ë¦¬"""
        print(f"ğŸ“‚ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì²˜ë¦¬ ì¤‘: {pts_file}")
        
        # ScaffoldDataProcessorë¡œ ì „ì²˜ë¦¬
        processed_data = self.data_processor.process_scaffold_pointcloud(pts_file)
        
        if processed_data is None:
            raise ValueError(f"í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì²˜ë¦¬ ì‹¤íŒ¨: {pts_file}")
        
        print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {processed_data['processed_shape']}")
        
        # í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ë¡œë“œ ë° í…ì„œ ë³€í™˜
        pts = load_pts(pts_file)
        if self.args.objaverse:
            pts[:, :3] = rotation(pts[:, :3], [0, 0, -90])
        
        pts_tensor = process_pts(pts, self.model.config).unsqueeze(0)
        model_device = next(self.model.parameters()).device
        pts_tensor = pts_tensor.to(model_device, dtype=torch.float16)
        
        return pts_tensor, processed_data
    
    def generate_response(self, prompt: str, pts_tensor: torch.Tensor) -> str:
        """LLM ì‘ë‹µ ìƒì„±"""
        
        # Point cloud token ì¶”ê°€
        if self.model.config.mm_use_pt_start_end:
            prompt = DEFAULT_PT_START_TOKEN + DEFAULT_POINT_TOKEN + DEFAULT_PT_END_TOKEN + '\n' + prompt
        else:
            prompt = DEFAULT_POINT_TOKEN + '\n' + prompt
        
        self.conv.append_message(self.conv.roles[0], prompt)
        self.conv.append_message(self.conv.roles[1], None)
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„± ë° í† í°í™”
        full_prompt = self.conv.get_prompt()
        input_ids = tokenizer_point_token(full_prompt, self.tokenizer, POINT_TOKEN_INDEX, return_tensors='pt').unsqueeze(0).cuda()
        
        # ì¤‘ë‹¨ ì¡°ê±´ ì„¤ì •
        stop_str = self.conv.sep if self.conv.sep_style != SeparatorStyle.TWO else self.conv.sep2
        keywords = [stop_str]
        stopping_criteria = KeywordsStoppingCriteria(keywords, self.tokenizer, input_ids)
        
        # ì‘ë‹µ ìƒì„±
        with torch.inference_mode():
            output_ids = self.model.generate(
                input_ids,
                points=pts_tensor,  # âœ… ìˆ˜ì •: point_clouds â†’ points
                do_sample=True if self.args.temperature > 0 else False,
                temperature=self.args.temperature,
                top_p=self.args.top_p,
                num_beams=self.args.num_beams,
                max_new_tokens=self.args.max_new_tokens,
                use_cache=True,
                stopping_criteria=[stopping_criteria]
            )
        
        # ì‘ë‹µ ë””ì½”ë”©
        input_token_len = input_ids.shape[1]
        n_diff_input_output = (input_ids != output_ids[:, :input_token_len]).sum().item()
        if n_diff_input_output > 0:
            print(f'[Warning] {n_diff_input_output} output_ids are not the same as the input_ids')
        
        outputs = self.tokenizer.batch_decode(output_ids[:, input_token_len:], skip_special_tokens=True)[0]
        outputs = outputs.strip()
        
        if outputs.endswith(stop_str):
            outputs = outputs[:-len(stop_str)]
        
        return outputs.strip()
    
    def run_analysis(self, pts_file: str, analysis_type: str = 'comprehensive') -> Dict[str, Any]:
        """ë¹„ê³„ ì•ˆì „ ë¶„ì„ ì‹¤í–‰"""
        start_time = time.time()
        
        print("ğŸ” ë¹„ê³„ ì•ˆì „ ë¶„ì„ ì‹œì‘...")
        print(f"ğŸ“‹ ë¶„ì„ ìœ í˜•: {analysis_type}")
        print("=" * 50)
        
        try:
            # 1. í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì²˜ë¦¬
            pts_tensor, processed_data = self.process_point_cloud(pts_file)
            
            # 2. ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì„ íƒ
            if analysis_type in self.safety_prompts:
                prompt = self.safety_prompts[analysis_type]
            else:
                prompt = self.safety_prompts['comprehensive']
            
            # 3. LLM ì‘ë‹µ ìƒì„±
            print("ğŸ§  AI ì•ˆì „ ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
            response = self.generate_response(prompt, pts_tensor)
            
            # 4. ê²°ê³¼ ì •ë¦¬
            end_time = time.time()
            
            result = {
                'scaffold_info': {
                    'file_path': pts_file,
                    'total_points': processed_data['processed_shape'][0],
                    'dimensions': processed_data['metadata'],
                    'processing_time': f"{end_time - start_time:.2f}ì´ˆ"
                },
                'pointlora_analysis': getattr(self, '_last_selection_info', {
                    'message': 'LoRA ì ìš©ë˜ì§€ ì•ŠìŒ'
                }),
                'ai_response': response,
                'analysis_type': analysis_type,
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
            }
            
            return result
            
        except Exception as e:
            print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'error': str(e),
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
            }
    
    def interactive_mode(self):
        """ëŒ€í™”í˜• ëª¨ë“œ ì‹¤í–‰"""
        print("ğŸ—ï¸ ScaffoldPointLoRA ë¹„ê³„ ì•ˆì „ ë¶„ì„ ëŒ€í™”í˜• ëª¨ë“œ")
        print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        print("=" * 50)
        
        # í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ë¡œë“œ
        if self.args.pts_file:
            try:
                pts_tensor, processed_data = self.process_point_cloud(self.args.pts_file)
                pts_loaded = True
                print(f"âœ… í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ë¡œë“œ ì™„ë£Œ: {self.args.pts_file}")
            except Exception as e:
                print(f"âŒ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ë¡œë“œ ì‹¤íŒ¨: {e}")
                pts_loaded = False
                pts_tensor = None
        else:
            pts_loaded = False
            pts_tensor = None
        
        # ëŒ€í™” ë£¨í”„
        used_pts = False
        
        while True:
            try:
                user_input = input(f"\n{self.conv.roles[0]}: ").strip()
                
                if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                    print("ğŸ‘‹ ë¶„ì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                
                if not user_input:
                    continue
                
                # ë¹ ë¥¸ ë¶„ì„ ëª…ë ¹ì–´ ì²˜ë¦¬
                if user_input in ['1', 'ì¢…í•©ë¶„ì„']:
                    user_input = self.safety_prompts['comprehensive']
                elif user_input in ['2', 'êµ¬ì¡°ë¶„ì„']:
                    user_input = self.safety_prompts['structural']
                elif user_input in ['3', 'í”Œë«í¼ë¶„ì„']:
                    user_input = self.safety_prompts['platform']
                elif user_input in ['4', 'ë†’ì´ë¶„ì„']:
                    user_input = self.safety_prompts['height_safety']
                
                print(f"{self.conv.roles[1]}: ", end="", flush=True)
                
                # Point cloud token ì¶”ê°€ (ì²˜ìŒ í•œ ë²ˆë§Œ)
                if pts_loaded and not used_pts:
                    if self.model.config.mm_use_pt_start_end:
                        user_input = DEFAULT_PT_START_TOKEN + DEFAULT_POINT_TOKEN + DEFAULT_PT_END_TOKEN + '\n' + user_input
                    else:
                        user_input = DEFAULT_POINT_TOKEN + '\n' + user_input
                    used_pts = True
                
                self.conv.append_message(self.conv.roles[0], user_input)
                self.conv.append_message(self.conv.roles[1], None)
                
                # ì‘ë‹µ ìƒì„±
                prompt = self.conv.get_prompt()
                input_ids = tokenizer_point_token(prompt, self.tokenizer, POINT_TOKEN_INDEX, return_tensors='pt').unsqueeze(0).cuda()
                
                stop_str = self.conv.sep if self.conv.sep_style != SeparatorStyle.TWO else self.conv.sep2
                keywords = [stop_str]
                stopping_criteria = KeywordsStoppingCriteria(keywords, self.tokenizer, input_ids)
                
                # ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥
                streamer = TextStreamer(self.tokenizer, skip_prompt=True, skip_special_tokens=True)
                
                with torch.inference_mode():
                    output_ids = self.model.generate(
                        input_ids,
                        points=pts_tensor if pts_loaded else None,  # âœ… ìˆ˜ì •: point_clouds â†’ points
                        do_sample=True if self.args.temperature > 0 else False,
                        temperature=self.args.temperature,
                        top_p=self.args.top_p,
                        num_beams=self.args.num_beams,
                        max_new_tokens=self.args.max_new_tokens,
                        use_cache=True,
                        stopping_criteria=[stopping_criteria],
                        streamer=streamer
                    )
                
                # ì‘ë‹µ ì €ì¥
                input_token_len = input_ids.shape[1]
                outputs = self.tokenizer.batch_decode(output_ids[:, input_token_len:], skip_special_tokens=True)[0]
                outputs = outputs.strip()
                if outputs.endswith(stop_str):
                    outputs = outputs[:-len(stop_str)]
                
                self.conv.messages[-1][-1] = outputs
                
                # ë¹ ë¥¸ ëª…ë ¹ì–´ ì•ˆë‚´ (ì²˜ìŒ í•œ ë²ˆë§Œ)
                if len(self.conv.messages) == 2:
                    print(f"\n\nğŸ’¡ ë¹ ë¥¸ ë¶„ì„: 1(ì¢…í•©) | 2(êµ¬ì¡°) | 3(í”Œë«í¼) | 4(ë†’ì´)")
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ ë¶„ì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue
    
    def single_analysis_mode(self, analysis_type: str, output_file: str = None):
        """ë‹¨ì¼ ë¶„ì„ ëª¨ë“œ"""
        if not self.args.pts_file:
            print("âŒ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ íŒŒì¼ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # ë¶„ì„ ì‹¤í–‰
        result = self.run_analysis(self.args.pts_file, analysis_type)
        
        if 'error' in result:
            print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {result['error']}")
            return
        
        # ê²°ê³¼ ì¶œë ¥
        self._print_analysis_result(result)
        
        # íŒŒì¼ ì €ì¥
        if output_file:
            try:
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                print(f"\nğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥: {output_file}")
            except Exception as e:
                print(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _print_analysis_result(self, result: Dict[str, Any]):
        """ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "=" * 60)
        print("ğŸ“Š ë¹„ê³„ ì•ˆì „ ë¶„ì„ ê²°ê³¼")
        print("=" * 60)
        
        # ê¸°ë³¸ ì •ë³´
        scaffold_info = result['scaffold_info']
        print(f"\nğŸ—ï¸ ë¹„ê³„ ì •ë³´:")
        print(f"   ğŸ“‚ íŒŒì¼: {Path(scaffold_info['file_path']).name}")
        print(f"   ğŸ“Š í¬ì¸íŠ¸ ìˆ˜: {scaffold_info['total_points']:,}ê°œ")
        print(f"   â±ï¸ ì²˜ë¦¬ ì‹œê°„: {scaffold_info['processing_time']}")
        
        # PointLoRA ë¶„ì„ ê²°ê³¼
        pointlora_info = result['pointlora_analysis']
        if 'total_selected' in pointlora_info:
            print(f"\nğŸ¯ PointLoRA ì•ˆì „ íŠ¹ì§• ë¶„ì„:")
            print(f"   ì„ íƒëœ ì•ˆì „ í† í°: {pointlora_info['total_selected']}ê°œ")
            print(f"   - ì „ì²´ êµ¬ì¡°: {pointlora_info['global_count']}ê°œ")
            print(f"   - êµ¬ì„±ìš”ì†Œ: {pointlora_info['component_count']}ê°œ")
            print(f"   - ì„¸ë¶€ì‚¬í•­: {pointlora_info['detail_count']}ê°œ")
        
        # AI ë¶„ì„ ê²°ê³¼
        print(f"\nğŸ¤– AI ì „ë¬¸ ì•ˆì „ ë¶„ì„:")
        print("-" * 40)
        ai_response = result['ai_response']
        # ì‘ë‹µì´ ë„ˆë¬´ ê¸¸ë©´ ì ì ˆíˆ ì¤„ë°”ê¿ˆ
        for line in ai_response.split('\n'):
            if line.strip():
                print(f"   {line}")
        
        print("\n" + "=" * 60)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ë¹„ê³„ ì•ˆì „ ê²€ì¦ íŠ¹í™” ShapeLLM CLI')
    
    # ëª¨ë¸ ê´€ë ¨ ì¸ì
    parser.add_argument("--model-path", type=str, default="qizekun/ShapeLLM_13B_general_v1.0")
    parser.add_argument("--model-base", type=str, default=None)
    parser.add_argument("--device", type=str, default="cuda")
    parser.add_argument("--conv-mode", type=str, default=None)
    parser.add_argument("--load-8bit", action="store_true")
    parser.add_argument("--load-4bit", action="store_true")
    
    # í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ê´€ë ¨
    parser.add_argument("--pts-file", type=str, help="ë¹„ê³„ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ íŒŒì¼ (.npy)")
    parser.add_argument("--objaverse", action="store_true", help="Objaverse ë°ì´í„° íšŒì „ ì ìš©")
    
    # ScaffoldPointLoRA ê´€ë ¨
    parser.add_argument("--use-scaffold-lora", action="store_true", default=True, help="ScaffoldPointLoRA ì‚¬ìš©")
    parser.add_argument("--scaffold-lora-rank", type=int, default=16, help="LoRA rank")
    parser.add_argument("--scaffold-lora-alpha", type=float, default=32.0, help="LoRA alpha")
    parser.add_argument("--training-stage", type=str, choices=['lora_only', 'full'], default='lora_only')
    
    # ìƒì„± ê´€ë ¨ ì¸ì
    parser.add_argument("--temperature", type=float, default=0.2)
    parser.add_argument("--top-p", type=float, default=None)
    parser.add_argument("--num-beams", type=int, default=1)
    parser.add_argument("--max-new-tokens", type=int, default=1024)
    
    # ì‹¤í–‰ ëª¨ë“œ ê´€ë ¨
    parser.add_argument("--analysis-type", type=str,
                       choices=['comprehensive', 'structural', 'platform', 'height_safety'],
                       default='comprehensive', help="ë¶„ì„ ìœ í˜•")
    parser.add_argument("--mode", type=str, choices=['interactive', 'single'], default='interactive',
                       help="ì‹¤í–‰ ëª¨ë“œ (interactive: ëŒ€í™”í˜•, single: ë‹¨ì¼ ë¶„ì„)")
    parser.add_argument("--output", type=str, help="ê²°ê³¼ ì €ì¥ íŒŒì¼ (JSON)")
    
    args = parser.parse_args()
    
    # ì…ë ¥ íŒŒì¼ í™•ì¸
    if args.mode == 'single' and not args.pts_file:
        print("âŒ single ëª¨ë“œì—ì„œëŠ” --pts-fileì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return
    
    if args.pts_file and not Path(args.pts_file).exists():
        print(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {args.pts_file}")
        return
    
    # CLI ì´ˆê¸°í™” ë° ì‹¤í–‰
    print("ğŸ—ï¸ ScaffoldPointLoRA ë¹„ê³„ ì•ˆì „ ë¶„ì„ ì‹œìŠ¤í…œ")
    print(f"ğŸ“‚ ëª¨ë¸: {args.model_path}")
    if args.pts_file:
        print(f"ğŸ“‚ ì…ë ¥ íŒŒì¼: {args.pts_file}")
    print(f"ğŸ¯ LoRA ì„¤ì •: rank={args.scaffold_lora_rank}, alpha={args.scaffold_lora_alpha}")
    print("=" * 60)
    
    try:
        # CLI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        cli = ScaffoldSafetyCLI(args)
        
        # ëª¨ë¸ ë¡œë”©
        cli.load_model()
        
        # ì‹¤í–‰ ëª¨ë“œì— ë”°ë¼ ë¶„ê¸°
        if args.mode == 'interactive':
            cli.interactive_mode()
        else:  # single ëª¨ë“œ
            cli.single_analysis_mode(args.analysis_type, args.output)
            
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()