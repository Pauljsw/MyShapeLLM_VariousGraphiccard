"""
ShapeLLMê³¼ ScaffoldPointLoRA í†µí•©
ê¸°ì¡´ ShapeLLMì˜ ReCon++ ì¸ì½”ë”ì™€ MLP í”„ë¡œì í„°ì— PointLoRA ì ìš©
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Optional, Dict, Any
import logging
from pathlib import Path

# í˜„ì¬ í”„ë¡œì íŠ¸ì˜ ShapeLLM ëª¨ë“ˆë“¤ import
# (ì‹¤ì œ ê²½ë¡œëŠ” í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ì¡°ì • í•„ìš”)
try:
    from llava.model.multimodal_encoder.clip_encoder import CLIPVisionTower
    from ReConV2.models.transformer import PatchEmbedding
    from ScaffoldPointLoRA import ScaffoldPointLoRA  # ìœ„ì—ì„œ êµ¬í˜„í•œ ëª¨ë“ˆ
except ImportError as e:
    print(f"Import ì˜¤ë¥˜: {e}")
    print("í”„ë¡œì íŠ¸ PYTHONPATH ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")


class ScaffoldEnhancedCLIPVisionTower(CLIPVisionTower):
    """
    ScaffoldPointLoRAê°€ í†µí•©ëœ ShapeLLMì˜ Vision Tower
    ê¸°ì¡´ ReCon++ ì¸ì½”ë”ì— PointLoRAë¥¼ ì ìš©í•˜ì—¬ ë¹„ê³„ ì•ˆì „ ë„ë©”ì¸ì— íŠ¹í™”
    """
    
    def __init__(self, vision_tower, args, delay_load=False):
        super().__init__(vision_tower, args, delay_load)
        
        # ScaffoldPointLoRA ì´ˆê¸°í™”
        self.scaffold_lora = None
        self.use_scaffold_lora = getattr(args, 'use_scaffold_lora', True)
        self.scaffold_lora_rank = getattr(args, 'scaffold_lora_rank', 16)
        self.scaffold_lora_alpha = getattr(args, 'scaffold_lora_alpha', 32.0)
        
        # í•™ìŠµ ëª¨ë“œ ì„¤ì •
        self.training_stage = getattr(args, 'training_stage', 'full')  # 'full', 'lora_only'
        
        logging.info(f"ScaffoldEnhanced CLIPVisionTower ì´ˆê¸°í™”")
        logging.info(f"use_scaffold_lora: {self.use_scaffold_lora}")
        logging.info(f"training_stage: {self.training_stage}")
    
    def load_model(self, device_map=None):
        """ëª¨ë¸ ë¡œë“œ í›„ ScaffoldPointLoRA ì ìš©"""
        # ê¸°ë³¸ ShapeLLM ëª¨ë¸ ë¡œë“œ
        super().load_model(device_map)
        
        if self.use_scaffold_lora:
            # ScaffoldPointLoRA ì´ˆê¸°í™” ë° ì ìš©
            self._setup_scaffold_lora()
            self._apply_scaffold_lora()
            self._freeze_non_lora_parameters()
            
            logging.info("ScaffoldPointLoRA ì ìš© ì™„ë£Œ")
            self._log_parameter_statistics()
    
    def _setup_scaffold_lora(self):
        """ScaffoldPointLoRA ì„¤ì •"""
        # ReCon++ì˜ hidden_size ì¶”ì¶œ (ì¼ë°˜ì ìœ¼ë¡œ 768 or 1024)
        if hasattr(self.vision_tower.model, 'embed'):
            hidden_size = self.vision_tower.model.embed.embed_dim
        else:
            hidden_size = 768  # ê¸°ë³¸ê°’
            
        self.scaffold_lora = ScaffoldPointLoRA(
            hidden_size=hidden_size,
            lora_rank=self.scaffold_lora_rank,
            lora_alpha=self.scaffold_lora_alpha,
            num_selected_tokens=40
        )
        
        # GPUë¡œ ì´ë™
        if hasattr(self.vision_tower, 'device'):
            self.scaffold_lora = self.scaffold_lora.to(self.vision_tower.device)
        else:
            self.scaffold_lora = self.scaffold_lora.to("cuda:0")
    
    def _apply_scaffold_lora(self):
        """ê¸°ì¡´ ShapeLLM ëª¨ë“ˆì— PointLoRA í†µí•©"""
        
        # 1. ReCon++ Transformer ë¸”ë¡ë“¤ì— LoRA ì ìš©
        self._integrate_transformer_lora()
        
        # 2. MLP Projection ë ˆì´ì–´ë“¤ì— LoRA ì ìš©  
        self._integrate_projection_lora()
        
        logging.info("ëª¨ë“  ë ˆì´ì–´ì— ScaffoldPointLoRA í†µí•© ì™„ë£Œ")
    
    def _integrate_transformer_lora(self):
        """ReCon++ Transformer ë¸”ë¡ë“¤ì— LoRA ì ìš©"""
        
        # ReCon++ ëª¨ë¸ì˜ transformer ë¸”ë¡ë“¤ ì°¾ê¸°
        if hasattr(self.vision_tower.model, 'blocks'):
            transformer_blocks = self.vision_tower.model.blocks
        elif hasattr(self.vision_tower.model, 'layers'):
            transformer_blocks = self.vision_tower.model.layers
        else:
            logging.warning("Transformer ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        for i, block in enumerate(transformer_blocks):
            # Self-Attention QKVì— LoRA ì ìš©
            if hasattr(block, 'attn'):
                self._wrap_attention_with_lora(block.attn, f"block_{i}")
            
            # FFNì— LoRA ì ìš©
            if hasattr(block, 'mlp'):
                self._wrap_ffn_with_lora(block.mlp, f"block_{i}")
    
    def _wrap_attention_with_lora(self, attention_module, block_name):
        """Attention ëª¨ë“ˆì„ LoRAë¡œ ê°ì‹¸ê¸°"""
        
        # ê¸°ì¡´ QKV projection ì €ì¥
        original_qkv = {}
        if hasattr(attention_module, 'qkv'):
            original_qkv['qkv'] = attention_module.qkv
        else:
            if hasattr(attention_module, 'q_proj'):
                original_qkv['q'] = attention_module.q_proj
            if hasattr(attention_module, 'k_proj'): 
                original_qkv['k'] = attention_module.k_proj
            if hasattr(attention_module, 'v_proj'):
                original_qkv['v'] = attention_module.v_proj
        
        # LoRA wrapper í•¨ìˆ˜ ìƒì„±
        def lora_attention_forward(original_forward):
            def wrapped_forward(x, *args, **kwargs):
                # ì›ë³¸ forward ì‹¤í–‰
                original_output = original_forward(x, *args, **kwargs)
                
                # ScaffoldPointLoRA ì ìš© (ì¢Œí‘œ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš°)
                if hasattr(self, '_current_point_coords') and self.scaffold_lora is not None:
                    lora_adaptations = self.scaffold_lora(
                        x, self._current_point_coords, mode='qkv_adaptation'
                    )
                    
                    # LoRA adaptationì„ ì›ë³¸ ì¶œë ¥ì— ì¶”ê°€
                    if isinstance(original_output, tuple):
                        adapted_output = original_output[0] + lora_adaptations['q'] + lora_adaptations['k'] + lora_adaptations['v']
                        return (adapted_output,) + original_output[1:]
                    else:
                        return original_output + lora_adaptations['q'] + lora_adaptations['k'] + lora_adaptations['v']
                
                return original_output
            return wrapped_forward
        
        # Forward í•¨ìˆ˜ ë˜í•‘
        attention_module.forward = lora_attention_forward(attention_module.forward)
        
        logging.debug(f"Attention LoRA ì ìš© ì™„ë£Œ: {block_name}")
    
    def _wrap_ffn_with_lora(self, ffn_module, block_name):
        """FFN ëª¨ë“ˆì„ LoRAë¡œ ê°ì‹¸ê¸°"""
        
        def lora_ffn_forward(original_forward):
            def wrapped_forward(x, *args, **kwargs):
                # ì›ë³¸ forward ì‹¤í–‰
                original_output = original_forward(x, *args, **kwargs)
                
                # ScaffoldPointLoRA FFN adaptation ì ìš©
                if hasattr(self, '_current_point_coords') and self.scaffold_lora is not None:
                    lora_adaptation = self.scaffold_lora(
                        x, self._current_point_coords, mode='ffn_adaptation'
                    )
                    
                    # LoRA adaptationì„ ì›ë³¸ ì¶œë ¥ì— ì¶”ê°€
                    return original_output + lora_adaptation['ffn_output']
                
                return original_output
            return wrapped_forward
        
        # Forward í•¨ìˆ˜ ë˜í•‘
        ffn_module.forward = lora_ffn_forward(ffn_module.forward)
        
        logging.debug(f"FFN LoRA ì ìš© ì™„ë£Œ: {block_name}")
    
    def _integrate_projection_lora(self):
        """MLP Projection ë ˆì´ì–´ë“¤ì— LoRA ì ìš©"""
        
        # ShapeLLMì˜ 3ê°œ í”„ë¡œì í„° ì°¾ê¸°: local, global, APE
        projection_modules = {}
        
        # ê°€ëŠ¥í•œ projection ëª¨ë“ˆë“¤ íƒìƒ‰
        for name, module in self.named_modules():
            if 'proj' in name.lower() or 'projection' in name.lower():
                if 'local' in name.lower():
                    projection_modules['local'] = module
                elif 'global' in name.lower():
                    projection_modules['global'] = module
                elif 'ape' in name.lower():
                    projection_modules['ape'] = module
        
        # ê° projectionì— LoRA ì ìš©
        for proj_name, proj_module in projection_modules.items():
            self._wrap_projection_with_lora(proj_module, proj_name)
    
    def _wrap_projection_with_lora(self, projection_module, proj_name):
        """Projection ëª¨ë“ˆì„ LoRAë¡œ ê°ì‹¸ê¸°"""
        
        def lora_projection_forward(original_forward):
            def wrapped_forward(x, *args, **kwargs):
                # ì›ë³¸ forward ì‹¤í–‰
                original_output = original_forward(x, *args, **kwargs)
                
                # ScaffoldPointLoRA projection adaptation ì ìš©
                if hasattr(self, '_current_point_coords') and self.scaffold_lora is not None:
                    lora_adaptations = self.scaffold_lora(
                        x, self._current_point_coords, mode='projection_adaptation'
                    )
                    
                    # í•´ë‹¹ projectionì˜ LoRA adaptation ì¶”ê°€
                    if proj_name in lora_adaptations:
                        return original_output + lora_adaptations[proj_name]
                    elif f"{proj_name}_projection" in lora_adaptations:
                        return original_output + lora_adaptations[f"{proj_name}_projection"]
                
                return original_output
            return wrapped_forward
        
        # Forward í•¨ìˆ˜ ë˜í•‘
        projection_module.forward = lora_projection_forward(projection_module.forward)
        
        logging.debug(f"Projection LoRA ì ìš© ì™„ë£Œ: {proj_name}")
    
    def _freeze_non_lora_parameters(self):
        """LoRAê°€ ì•„ë‹Œ ë§¤ê°œë³€ìˆ˜ë“¤ ê³ ì •"""
        
        if self.training_stage == 'lora_only':
            # ëª¨ë“  ê¸°ì¡´ ë§¤ê°œë³€ìˆ˜ ê³ ì •
            for param in self.vision_tower.parameters():
                param.requires_grad = False
            
            # LoRA ë§¤ê°œë³€ìˆ˜ë§Œ í•™ìŠµ ê°€ëŠ¥í•˜ê²Œ ì„¤ì •
            if self.scaffold_lora is not None:
                for param in self.scaffold_lora.get_trainable_parameters():
                    param.requires_grad = True
            
            logging.info("LoRA-only ëª¨ë“œ: ê¸°ì¡´ ë§¤ê°œë³€ìˆ˜ ê³ ì •, LoRA ë§¤ê°œë³€ìˆ˜ë§Œ í•™ìŠµ")
        
        elif self.training_stage == 'full':
            # ì „ì²´ fine-tuning (ê¸°ë³¸ ShapeLLM ë°©ì‹)
            logging.info("Full fine-tuning ëª¨ë“œ: ëª¨ë“  ë§¤ê°œë³€ìˆ˜ í•™ìŠµ")
    
    def _log_parameter_statistics(self):
        """ë§¤ê°œë³€ìˆ˜ í†µê³„ ë¡œê¹…"""
        if self.scaffold_lora is not None:
            param_info = self.scaffold_lora.get_parameter_count()
            
            # ì „ì²´ ëª¨ë¸ ë§¤ê°œë³€ìˆ˜ ê³„ì‚°
            total_model_params = sum(p.numel() for p in self.parameters())
            trainable_model_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
            
            logging.info("=== ë§¤ê°œë³€ìˆ˜ í†µê³„ ===")
            logging.info(f"ì „ì²´ ëª¨ë¸ ë§¤ê°œë³€ìˆ˜: {total_model_params:,}")
            logging.info(f"í›ˆë ¨ ê°€ëŠ¥ ë§¤ê°œë³€ìˆ˜: {trainable_model_params:,}")
            logging.info(f"LoRA ë§¤ê°œë³€ìˆ˜: {param_info['trainable_parameters']:,}")
            logging.info(f"í›ˆë ¨ íš¨ìœ¨ì„±: {trainable_model_params/total_model_params:.2%}")
            logging.info(f"ë©”ëª¨ë¦¬ ì ˆì•½: {1-(trainable_model_params/total_model_params):.2%}")
    
    @torch.no_grad()
    def forward(self, pts):
        """
        ScaffoldPointLoRAê°€ ì ìš©ëœ forward pass
        """
        print("ğŸ—ï¸ [DEBUG] ScaffoldEnhanced CLIPVisionTower.forward() called")
        
        # í¬ì¸íŠ¸ ì¢Œí‘œ ì •ë³´ ì €ì¥ (LoRAì—ì„œ ì‚¬ìš©)
        if isinstance(pts, list):
            # ì²« ë²ˆì§¸ í¬ì¸íŠ¸ í´ë¼ìš°ë“œì˜ ì¢Œí‘œ ì‚¬ìš© (xyz)
            if len(pts) > 0 and pts[0].shape[-1] >= 3:
                self._current_point_coords = pts[0][:, :, :3].unsqueeze(0)  # [1, N, 3]
        elif pts.shape[-1] >= 3:
            self._current_point_coords = pts[:, :, :3]  # [B, N, 3]
        
        # Multi-scale token selection ìˆ˜í–‰
        if self.scaffold_lora is not None and hasattr(self, '_current_point_coords'):
            
            # ê¸°ë³¸ features ì¶”ì¶œ (ë¶€ëª¨ í´ë˜ìŠ¤ forward í˜¸ì¶œ ì „ì— ë¯¸ë¦¬ ì¤€ë¹„)
            if isinstance(pts, list):
                point_features_list = []
                for pt in pts:
                    # ê°„ë‹¨í•œ embeddingìœ¼ë¡œ ì´ˆê¸° features ìƒì„±
                    feat = torch.randn(1, pt.shape[0], self.scaffold_lora.hidden_size).to(pt.device)
                    point_features_list.append(feat)
                point_features = point_features_list[0]  # ì²« ë²ˆì§¸ ì‚¬ìš©
            else:
                point_features = torch.randn(pts.shape[0], pts.shape[1], self.scaffold_lora.hidden_size).to(pts.device)
            
            # Multi-scale token selection
            selection_result = self.scaffold_lora(
                point_features, self._current_point_coords, mode='token_selection'
            )
            
            print(f"ğŸ¯ ì„ íƒëœ í† í° ìˆ˜: {selection_result['selected_tokens'].shape[1]}")
            print(f"ğŸ¯ ì„ íƒ ì •ë³´: {selection_result['selection_info']}")
        
        # ê¸°ë³¸ ShapeLLM forward ì‹¤í–‰ (LoRAê°€ ìë™ìœ¼ë¡œ ì ìš©ë¨)
        return super().forward(pts)


def create_scaffold_enhanced_shapellm(model_path: str, **kwargs):
    """
    ScaffoldPointLoRAê°€ ì ìš©ëœ ShapeLLM ìƒì„±
    
    Args:
        model_path: ShapeLLM ëª¨ë¸ ê²½ë¡œ
        **kwargs: ì¶”ê°€ ì„¤ì • (lora_rank, lora_alpha, training_stage ë“±)
    """
    
    # ì„¤ì • í´ë˜ìŠ¤ ìƒì„±
    class ScaffoldConfig:
        def __init__(self, **kwargs):
            self.use_scaffold_lora = kwargs.get('use_scaffold_lora', True)
            self.scaffold_lora_rank = kwargs.get('scaffold_lora_rank', 16)
            self.scaffold_lora_alpha = kwargs.get('scaffold_lora_alpha', 32.0)
            self.training_stage = kwargs.get('training_stage', 'lora_only')  # 'lora_only' or 'full'
    
    config = ScaffoldConfig(**kwargs)
    
    try:
        # ê¸°ì¡´ ShapeLLM ëª¨ë¸ ë¡œë“œ
        from transformers import AutoModel, AutoTokenizer
        
        print(f"ğŸ—ï¸ ScaffoldEnhanced ShapeLLM ë¡œë”© ì¤‘: {model_path}")
        
        # ì›ë³¸ vision tower ìƒì„±
        vision_tower = CLIPVisionTower('openai/clip-vit-large-patch14', config)
        
        # ScaffoldPointLoRAë¡œ í–¥ìƒëœ vision towerë¡œ êµì²´
        enhanced_vision_tower = ScaffoldEnhancedCLIPVisionTower('openai/clip-vit-large-patch14', config)
        enhanced_vision_tower.load_model()
        
        print("âœ… ScaffoldEnhanced ShapeLLM ë¡œë”© ì™„ë£Œ")
        return enhanced_vision_tower
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None


def save_scaffold_lora_weights(model, save_path: str):
    """
    ScaffoldPointLoRA ê°€ì¤‘ì¹˜ë§Œ ì €ì¥ (íš¨ìœ¨ì  ì €ì¥)
    
    Args:
        model: ScaffoldEnhancedCLIPVisionTower
        save_path: ì €ì¥ ê²½ë¡œ
    """
    if hasattr(model, 'scaffold_lora') and model.scaffold_lora is not None:
        lora_state_dict = {}
        
        # LoRA ë§¤ê°œë³€ìˆ˜ë§Œ ì¶”ì¶œ
        for name, param in model.scaffold_lora.named_parameters():
            if param.requires_grad:
                lora_state_dict[name] = param.data.cpu()
        
        # ì„¤ì • ì •ë³´ë„ í•¨ê»˜ ì €ì¥
        save_dict = {
            'lora_state_dict': lora_state_dict,
            'config': {
                'scaffold_lora_rank': model.scaffold_lora_rank,
                'scaffold_lora_alpha': model.scaffold_lora_alpha,
                'training_stage': model.training_stage,
                'hidden_size': model.scaffold_lora.hidden_size
            }
        }
        
        torch.save(save_dict, save_path)
        print(f"âœ… LoRA ê°€ì¤‘ì¹˜ ì €ì¥ ì™„ë£Œ: {save_path}")
        print(f"ğŸ“Š ì €ì¥ëœ ë§¤ê°œë³€ìˆ˜ ìˆ˜: {len(lora_state_dict):,}")
    else:
        print("âŒ ScaffoldPointLoRAê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")


def load_scaffold_lora_weights(model, load_path: str):
    """
    ì €ì¥ëœ ScaffoldPointLoRA ê°€ì¤‘ì¹˜ ë¡œë“œ
    
    Args:
        model: ScaffoldEnhancedCLIPVisionTower
        load_path: ë¡œë“œ ê²½ë¡œ
    """
    if not Path(load_path).exists():
        print(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {load_path}")
        return False
    
    try:
        checkpoint = torch.load(load_path, map_location='cpu')
        lora_state_dict = checkpoint['lora_state_dict']
        config = checkpoint.get('config', {})
        
        if hasattr(model, 'scaffold_lora') and model.scaffold_lora is not None:
            # LoRA ê°€ì¤‘ì¹˜ ë¡œë“œ
            missing_keys, unexpected_keys = model.scaffold_lora.load_state_dict(lora_state_dict, strict=False)
            
            print(f"âœ… LoRA ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ: {load_path}")
            print(f"ğŸ“Š ë¡œë“œëœ ë§¤ê°œë³€ìˆ˜ ìˆ˜: {len(lora_state_dict):,}")
            if missing_keys:
                print(f"âš ï¸ ëˆ„ë½ëœ í‚¤: {missing_keys}")
            if unexpected_keys:
                print(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ í‚¤: {unexpected_keys}")
            
            return True
        else:
            print("âŒ ScaffoldPointLoRAê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
            return False
            
    except Exception as e:
        print(f"âŒ LoRA ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False


# ë¹„ê³„ ë°ì´í„°ì…‹ ì²˜ë¦¬ë¥¼ ìœ„í•œ ìœ í‹¸ë¦¬í‹°
class ScaffoldDataProcessor:
    """
    ë¹„ê³„ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ë°ì´í„° ì „ì²˜ë¦¬ ë° ì¦ê°•
    """
    
    def __init__(self, target_points: int = 8192):
        self.target_points = target_points
        
        # ë¹„ê³„ ì•ˆì „ ê²€ì‚¬ í•­ëª©ë“¤
        self.safety_checkpoints = {
            'structural_integrity': ['joints', 'connections', 'support_posts'],
            'working_platform': ['platform_surface', 'guardrails', 'access_points'],
            'height_safety': ['fall_protection', 'ladder_safety', 'vertical_spacing'],
            'material_condition': ['corrosion', 'damage', 'wear_patterns']
        }
    
    def process_scaffold_pointcloud(self, pts_file: str) -> Dict[str, Any]:
        """
        ë¹„ê³„ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì²˜ë¦¬
        
        Args:
            pts_file: .npy í¬ì¸íŠ¸ í´ë¼ìš°ë“œ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            dict: ì²˜ë¦¬ëœ ë°ì´í„°ì™€ ë©”íƒ€ì •ë³´
        """
        try:
            # í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ë¡œë“œ
            points = np.load(pts_file)
            print(f"ğŸ“‚ ì›ë³¸ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ shape: {points.shape}")
            
            # ì¢Œí‘œ ì •ê·œí™”
            coords = points[:, :3]  # x, y, z
            colors = points[:, 3:6] if points.shape[1] >= 6 else None
            
            # í¬ì¸íŠ¸ ìˆ˜ ì¡°ì •
            if len(coords) > self.target_points:
                # ë‹¤ìš´ìƒ˜í”Œë§ (FPS ì‚¬ìš©)
                indices = self._farthest_point_sample(coords, self.target_points)
                coords = coords[indices]
                if colors is not None:
                    colors = colors[indices]
            elif len(coords) < self.target_points:
                # ì—…ìƒ˜í”Œë§ (ë³µì œ + ë…¸ì´ì¦ˆ)
                coords = self._upsample_points(coords, self.target_points)
                if colors is not None:
                    colors = self._upsample_points(colors, self.target_points)
            
            # ì¢Œí‘œ ì •ê·œí™” (-1 ~ 1)
            coords_normalized = self._normalize_coordinates(coords)
            
            # ìµœì¢… í¬ì¸íŠ¸ í´ë¼ìš°ë“œ êµ¬ì„±
            if colors is not None:
                final_points = np.concatenate([coords_normalized, colors], axis=1)
            else:
                # ìƒ‰ìƒ ì •ë³´ê°€ ì—†ìœ¼ë©´ dummy ìƒì„±
                dummy_colors = np.ones((len(coords_normalized), 3)) * 0.5
                final_points = np.concatenate([coords_normalized, dummy_colors], axis=1)
            
            # ë©”íƒ€ ì •ë³´ ì¶”ì¶œ
            metadata = self._extract_scaffold_metadata(coords_normalized)
            
            return {
                'points': final_points,
                'coordinates': coords_normalized,
                'colors': colors,
                'metadata': metadata,
                'original_shape': points.shape,
                'processed_shape': final_points.shape
            }
            
        except Exception as e:
            print(f"âŒ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None
    
    def _farthest_point_sample(self, points: np.ndarray, num_samples: int) -> np.ndarray:
        """Farthest Point Sampling"""
        n_points = len(points)
        indices = np.zeros(num_samples, dtype=int)
        distances = np.full(n_points, float('inf'))
        
        # ì²« ë²ˆì§¸ ì ì€ ëœë¤ ì„ íƒ
        indices[0] = np.random.randint(0, n_points)
        
        for i in range(1, num_samples):
            # ë§ˆì§€ë§‰ ì„ íƒëœ ì ì—ì„œ ëª¨ë“  ì ê¹Œì§€ì˜ ê±°ë¦¬ ê³„ì‚°
            last_point = points[indices[i-1]]
            dists = np.linalg.norm(points - last_point, axis=1)
            distances = np.minimum(distances, dists)
            
            # ê°€ì¥ ë¨¼ ì  ì„ íƒ
            indices[i] = np.argmax(distances)
            distances[indices[i]] = 0
            
        return indices
    
    def _upsample_points(self, points: np.ndarray, target_size: int) -> np.ndarray:
        """í¬ì¸íŠ¸ ì—…ìƒ˜í”Œë§ (ë³µì œ + ë…¸ì´ì¦ˆ)"""
        current_size = len(points)
        repeat_times = target_size // current_size + 1
        
        # í¬ì¸íŠ¸ ë³µì œ
        repeated = np.tile(points, (repeat_times, 1))[:target_size]
        
        # ì‘ì€ ë…¸ì´ì¦ˆ ì¶”ê°€
        noise = np.random.normal(0, 0.01, repeated.shape)
        upsampled = repeated + noise
        
        return upsampled
    
    def _normalize_coordinates(self, coords: np.ndarray) -> np.ndarray:
        """ì¢Œí‘œ ì •ê·œí™” (-1 ~ 1)"""
        min_vals = coords.min(axis=0)
        max_vals = coords.max(axis=0)
        ranges = max_vals - min_vals
        
        # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
        ranges[ranges == 0] = 1.0
        
        normalized = 2 * (coords - min_vals) / ranges - 1
        return normalized
    
    def _extract_scaffold_metadata(self, coords: np.ndarray) -> Dict[str, Any]:
        """ë¹„ê³„ êµ¬ì¡° ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        metadata = {}
        
        # ê¸°ë³¸ í†µê³„
        metadata['height_range'] = [coords[:, 2].min(), coords[:, 2].max()]
        metadata['width_range'] = [coords[:, 0].min(), coords[:, 0].max()]
        metadata['depth_range'] = [coords[:, 1].min(), coords[:, 1].max()]
        
        # ë†’ì´ë³„ ë°€ë„ ë¶„ì„ (ì¸µë³„ êµ¬ì¡° íŒŒì•…)
        height_bins = np.linspace(coords[:, 2].min(), coords[:, 2].max(), 10)
        height_density, _ = np.histogram(coords[:, 2], bins=height_bins)
        metadata['height_density'] = height_density.tolist()
        
        # ìˆ˜ì§ êµ¬ì¡° ê°ì§€ (ê¸°ë‘¥, ì§€ì§€ëŒ€)
        vertical_variance = np.var(coords[:, :2], axis=0)  # x, y ì¶• ë¶„ì‚°
        metadata['vertical_structure_strength'] = float(np.mean(vertical_variance))
        
        # ìˆ˜í‰ êµ¬ì¡° ê°ì§€ (í”Œë«í¼, ì‘ì—…ë©´)
        z_variance = np.var(coords[:, 2])
        metadata['horizontal_structure_strength'] = float(z_variance)
        
        return metadata


# í…ŒìŠ¤íŠ¸ ë° ì‹¤í–‰ í•¨ìˆ˜
def test_scaffold_integration():
    """ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸"""
    print("ğŸ—ï¸ ScaffoldPointLoRA + ShapeLLM í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # 1. ë°ì´í„° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    processor = ScaffoldDataProcessor()
    
    # ì‹¤ì œ ë¹„ê³„ ë°ì´í„°ê°€ ìˆë‹¤ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ë”ë¯¸ ë°ì´í„° ìƒì„±
    scaffold_file = "assets/SW_Scaffold_8192.npy"
    if Path(scaffold_file).exists():
        print(f"ğŸ“‚ ì‹¤ì œ ë¹„ê³„ ë°ì´í„° ë¡œë“œ: {scaffold_file}")
        processed_data = processor.process_scaffold_pointcloud(scaffold_file)
    else:
        print("ğŸ“‚ ë”ë¯¸ ë¹„ê³„ ë°ì´í„° ìƒì„±")
        # ë”ë¯¸ ë¹„ê³„ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„±
        dummy_points = np.random.randn(8192, 6)
        np.save("dummy_scaffold.npy", dummy_points)
        processed_data = processor.process_scaffold_pointcloud("dummy_scaffold.npy")
    
    if processed_data:
        print(f"âœ… ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ:")
        print(f"   - ì›ë³¸ shape: {processed_data['original_shape']}")
        print(f"   - ì²˜ë¦¬ í›„ shape: {processed_data['processed_shape']}")
        print(f"   - ë©”íƒ€ë°ì´í„°: {list(processed_data['metadata'].keys())}")
    
    # 2. ScaffoldEnhanced ShapeLLM ìƒì„±
    enhanced_model = create_scaffold_enhanced_shapellm(
        model_path="qizekun/ShapeLLM_13B_general_v1.0",
        use_scaffold_lora=True,
        scaffold_lora_rank=16,
        scaffold_lora_alpha=32.0,
        training_stage='lora_only'
    )
    
    if enhanced_model:
        print("âœ… ScaffoldEnhanced ShapeLLM ìƒì„± ì™„ë£Œ")
        
        # 3. í…ŒìŠ¤íŠ¸ forward pass
        if processed_data:
            test_points = torch.FloatTensor(processed_data['points']).unsqueeze(0)  # [1, N, 6]
            
            try:
                with torch.no_grad():
                    output = enhanced_model(test_points)
                print("âœ… Forward pass í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
                print(f"   - ì¶œë ¥ íƒ€ì…: {type(output)}")
                if hasattr(output, 'shape'):
                    print(f"   - ì¶œë ¥ shape: {output.shape}")
            except Exception as e:
                print(f"âŒ Forward pass ì‹¤íŒ¨: {e}")
    
    print("ğŸ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ")


if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(level=logging.INFO)
    
    # í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_scaffold_integration()
