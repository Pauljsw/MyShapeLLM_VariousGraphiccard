# íŒŒì¼ ê´€ë¦¬ ë° ìˆ˜ì • ê³„íš
# scaffold_safety_ai í”„ë¡œì íŠ¸ì˜ ê¸°ì¡´ íŒŒì¼ ì²˜ë¦¬ ë°©ë²•

# ============================================================================
# 1. ê¸°ì¡´ íŒŒì¼ ë°±ì—… ë° ìˆ˜ì •
# ============================================================================

# í˜„ìž¬ ìœ„ì¹˜ë¡œ ì´ë™
cd scaffold_safety_ai

# ê¸°ì¡´ íŒŒì¼ ë°±ì—…
echo "ðŸ“¦ Backing up existing files..."
cp src/integrate_shapellm.py src/integrate_shapellm_backup.py
echo "âœ… Backup created: src/integrate_shapellm_backup.py"

# ============================================================================
# 2. ìˆ˜ì •ëœ integrate_shapellm.py ìƒì„±
# ============================================================================

cat > src/integrate_shapellm_fixed.py << 'EOF'
# src/integrate_shapellm_fixed.py
# ìˆ˜ì •ëœ ShapeLLM í†µí•© - ê¸°ì¡´ ì˜¤ë¥˜ í•´ê²°

import torch
import torch.nn as nn
import sys
import os
from pathlib import Path

# PointLoRA í•µì‹¬ ëª¨ë“ˆ import (ê¸°ì¡´ íŒŒì¼ ì‚¬ìš©)
from .pointlora_core import LoRALayer, SafetyTokenSelector

class SafeShapeLLMIntegration:
    """
    ì•ˆì „í•œ ShapeLLM í†µí•© ë°©ì‹
    ê¸°ì¡´ ì½”ë“œì˜ import ì˜¤ë¥˜ì™€ êµ¬ì¡°ì  ë¬¸ì œ í•´ê²°
    """
    
    def __init__(self, shapellm_path: str = None):
        self.shapellm_path = Path(shapellm_path) if shapellm_path else Path.cwd()
        self.setup_environment()
        
    def setup_environment(self):
        """ShapeLLM í™˜ê²½ ì•ˆì „í•˜ê²Œ ì„¤ì •"""
        try:
            # ShapeLLM ê²½ë¡œë¥¼ Python pathì— ì¶”ê°€
            if str(self.shapellm_path) not in sys.path:
                sys.path.insert(0, str(self.shapellm_path))
            
            # í•„ìš”í•œ ë””ë ‰í† ë¦¬ í™•ì¸
            required_dirs = ['llava', 'llava/model', 'llava/serve']
            for dir_name in required_dirs:
                dir_path = self.shapellm_path / dir_name
                if not dir_path.exists():
                    print(f"âš ï¸ Warning: {dir_name} not found at {self.shapellm_path}")
            
            print(f"âœ… ShapeLLM environment setup complete")
            return True
            
        except Exception as e:
            print(f"âŒ Environment setup failed: {e}")
            return False

class ScaffoldSafetyWrapper(nn.Module):
    """
    ê¸°ì¡´ ì½”ë“œ ë¬¸ì œì ì„ í•´ê²°í•œ Scaffold Safety ëž˜í¼
    """
    
    def __init__(self, config: dict = None):
        super().__init__()
        
        # ê¸°ë³¸ ì„¤ì •
        self.config = config or {
            'lora_rank': 16,
            'lora_alpha': 32,
            'safety_token_count': 40,
            'feature_dim': 768
        }
        
        # PointLoRA êµ¬ì„± ìš”ì†Œë“¤ (ê¸°ì¡´ pointlora_core.py ì‚¬ìš©)
        self.safety_selector = SafetyTokenSelector(
            feature_dim=self.config['feature_dim'],
            safety_token_count=self.config['safety_token_count']
        )
        
        # Safety classifier ì¶”ê°€
        self.safety_classifier = nn.Sequential(
            nn.LayerNorm(self.config['feature_dim']),
            nn.Linear(self.config['feature_dim'], self.config['feature_dim'] // 2),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(self.config['feature_dim'] // 2, 3)  # safe, warning, danger
        )
        
        # LoRA layers storage
        self.lora_layers = nn.ModuleDict()
        
        # Mock feature extractor (ì‹¤ì œë¡œëŠ” ShapeLLM ì‚¬ìš©)
        self.mock_feature_extractor = self._create_mock_feature_extractor()
        
        print(f"âœ… ScaffoldSafetyWrapper initialized")
        self._print_parameter_stats()
    
    def _create_mock_feature_extractor(self):
        """Mock feature extractor for testing"""
        return nn.Sequential(
            nn.Linear(6, 256),  # xyz+rgb input
            nn.ReLU(),
            nn.Linear(256, self.config['feature_dim']),
            nn.LayerNorm(self.config['feature_dim'])
        )
    
    def add_lora_layer(self, layer_name: str, in_features: int, out_features: int):
        """ë™ì ìœ¼ë¡œ LoRA ë ˆì´ì–´ ì¶”ê°€"""
        lora_layer = LoRALayer(
            in_features=in_features,
            out_features=out_features,
            rank=self.config['lora_rank'],
            alpha=self.config['lora_alpha']
        )
        self.lora_layers[layer_name] = lora_layer
        print(f"âœ… LoRA layer added: {layer_name} ({lora_layer.get_param_count():,} params)")
    
    def forward_safety_analysis(self, point_cloud: torch.Tensor):
        """Safety analysis forward pass"""
        batch_size, num_points, point_dim = point_cloud.shape
        
        # 1. Feature extraction (Mock)
        # ì‹¤ì œë¡œëŠ” ShapeLLMì˜ ReCon++ encoder ì‚¬ìš©
        if num_points > 512:
            # Simple downsampling for mock
            indices = torch.randperm(num_points)[:512]
            sampled_points = point_cloud[:, indices, :]
        else:
            sampled_points = point_cloud
        
        # Mock feature extraction
        features = self.mock_feature_extractor(sampled_points)  # [batch, 512, 768]
        
        # 2. Safety token selection
        safety_tokens, safety_indices = self.safety_selector(features)
        
        # 3. Safety classification
        avg_safety_features = safety_tokens.mean(dim=1)
        safety_logits = self.safety_classifier(avg_safety_features)
        safety_probs = torch.softmax(safety_logits, dim=-1)
        
        return {
            'safety_tokens': safety_tokens,      # [batch, 40, 768] - Aì•ˆâ†’Bì•ˆ ì—°ê²°ìš©!
            'safety_indices': safety_indices,   # [batch, 40]
            'safety_logits': safety_logits,     # [batch, 3]
            'safety_probs': safety_probs,       # [batch, 3]
            'features': features,               # [batch, 512, 768]
            'predicted_class': torch.argmax(safety_probs, dim=-1),
            'confidence': torch.max(safety_probs, dim=-1)[0]
        }
    
    def set_training_mode(self, scaffold_training: bool = True):
        """LoRAì™€ Safety ëª¨ë“ˆë§Œ í›ˆë ¨ ëª¨ë“œë¡œ ì„¤ì •"""
        # ì „ì²´ ëª¨ë¸ freeze
        for param in self.parameters():
            param.requires_grad = False
        
        if scaffold_training:
            # LoRAì™€ Safety ëª¨ë“ˆë§Œ í•™ìŠµ ê°€ëŠ¥
            for name, param in self.named_parameters():
                if any(keyword in name for keyword in ['lora', 'safety']):
                    param.requires_grad = True
        
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        total_params = sum(p.numel() for p in self.parameters())
        
        print(f"ðŸŽ¯ Training mode set:")
        print(f"   Trainable: {trainable_params:,} ({trainable_params/total_params*100:.2f}%)")
    
    def _print_parameter_stats(self):
        """íŒŒë¼ë¯¸í„° í†µê³„ ì¶œë ¥"""
        total_params = sum(p.numel() for p in self.parameters())
        lora_params = sum(p.numel() for name, p in self.named_parameters() if 'lora' in name)
        safety_params = sum(p.numel() for name, p in self.named_parameters() if 'safety' in name)
        
        print(f"ðŸ“Š Parameter Statistics:")
        print(f"   Total: {total_params:,}")
        print(f"   LoRA: {lora_params:,}")
        print(f"   Safety: {safety_params:,}")
        print(f"   Trainable: {lora_params + safety_params:,}")

def create_scaffold_model(config: dict = None):
    """Scaffold Safety ëª¨ë¸ ìƒì„± í•¨ìˆ˜"""
    return ScaffoldSafetyWrapper(config)

# ============================================================================
# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤
# ============================================================================

def test_fixed_integration():
    """ìˆ˜ì •ëœ í†µí•© ì½”ë“œ í…ŒìŠ¤íŠ¸"""
    print("ðŸ§ª Testing Fixed Integration...")
    
    # 1. í™˜ê²½ ì„¤ì • í…ŒìŠ¤íŠ¸
    integration = SafeShapeLLMIntegration()
    
    # 2. ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸
    config = {
        'lora_rank': 16,
        'lora_alpha': 32,
        'safety_token_count': 40,
        'feature_dim': 768
    }
    
    model = create_scaffold_model(config)
    
    # 3. LoRA ë ˆì´ì–´ ì¶”ê°€ í…ŒìŠ¤íŠ¸
    model.add_lora_layer('attention_qkv', 768, 768*3)
    model.add_lora_layer('mlp_fc1', 768, 3072)
    
    # 4. í›ˆë ¨ ëª¨ë“œ ì„¤ì •
    model.set_training_mode(scaffold_training=True)
    
    # 5. Forward pass í…ŒìŠ¤íŠ¸
    test_point_cloud = torch.randn(2, 8192, 6)  # batch=2, points=8192, xyz+rgb
    
    with torch.no_grad():
        results = model.forward_safety_analysis(test_point_cloud)
    
    print(f"âœ… Test Results:")
    print(f"   Safety tokens: {results['safety_tokens'].shape}")
    print(f"   Predicted classes: {results['predicted_class']}")
    print(f"   Confidence: {results['confidence']}")
    
    return model, results

if __name__ == "__main__":
    # ìˆ˜ì •ëœ í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    model, results = test_fixed_integration()
    print("âœ… Fixed integration test completed!")
EOF

# ============================================================================
# 3. ìƒˆ íŒŒì¼ë“¤ ìƒì„±
# ============================================================================

# í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p tests

# í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
cat > tests/test_integration.py << 'EOF'
# tests/test_integration.py
# í†µí•© í…ŒìŠ¤íŠ¸

import sys
import os
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.integrate_shapellm_fixed import test_fixed_integration, create_scaffold_model
from src.pointlora_core import test_pointlora_components

def test_all_components():
    """ëª¨ë“  êµ¬ì„± ìš”ì†Œ í…ŒìŠ¤íŠ¸"""
    print("ðŸ§ª Running Complete Integration Tests")
    print("=" * 50)
    
    # 1. ê¸°ë³¸ PointLoRA êµ¬ì„± ìš”ì†Œ í…ŒìŠ¤íŠ¸
    print("\nðŸ“‹ Step 1: Testing PointLoRA components...")
    try:
        test_pointlora_components()
        print("âœ… PointLoRA components test passed")
    except Exception as e:
        print(f"âŒ PointLoRA test failed: {e}")
        return False
    
    # 2. ìˆ˜ì •ëœ í†µí•© í…ŒìŠ¤íŠ¸
    print("\nðŸ“‹ Step 2: Testing fixed integration...")
    try:
        model, results = test_fixed_integration()
        print("âœ… Fixed integration test passed")
    except Exception as e:
        print(f"âŒ Integration test failed: {e}")
        return False
    
    # 3. Aì•ˆâ†’Bì•ˆ ì—°ê²° í…ŒìŠ¤íŠ¸
    print("\nðŸ“‹ Step 3: Testing Stage Aâ†’B connection...")
    try:
        safety_tokens = results['safety_tokens']
        print(f"   Safety tokens ready for Stage B: {safety_tokens.shape}")
        print("âœ… Stage Aâ†’B connection ready")
    except Exception as e:
        print(f"âŒ Stage connection test failed: {e}")
        return False
    
    print("\nðŸŽ‰ All tests passed! Ready for training.")
    return True

if __name__ == "__main__":
    success = test_all_components()
    if success:
        print("\nðŸš€ Ready to proceed with Stage A training!")
    else:
        print("\nâš ï¸ Some tests failed. Please check the issues above.")
EOF

# ìŠ¤í¬ë¦½íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p scripts

# ê°„ë‹¨í•œ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
cat > scripts/run_tests.py << 'EOF'
# scripts/run_tests.py
# ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰

import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from tests.test_integration import test_all_components

if __name__ == "__main__":
    print("ðŸš€ Running all scaffold safety tests...")
    success = test_all_components()
    
    if success:
        print("\nâœ… All systems ready!")
        print("Next steps:")
        print("1. Run Stage A training: python scripts/train_stage_a.py")
        print("2. Prepare real scaffold data")
        print("3. Integrate with actual ShapeLLM")
    else:
        print("\nâŒ Tests failed. Please fix issues first.")
EOF

# ============================================================================
# 4. ì‹¤í–‰ ê°€ì´ë“œ
# ============================================================================

echo ""
echo "ðŸ“ File Management Complete!"
echo "============================="
echo ""
echo "ðŸ“‹ Current file structure:"
echo "scaffold_safety_ai/"
echo "â”œâ”€â”€ src/"
echo "â”‚   â”œâ”€â”€ pointlora_core.py           # âœ… ìœ ì§€ (ê¸°ì¡´)"
echo "â”‚   â”œâ”€â”€ integrate_shapellm.py       # âš ï¸ ì›ë³¸ (ë¬¸ì œ ìžˆìŒ)"
echo "â”‚   â”œâ”€â”€ integrate_shapellm_backup.py # ðŸ“¦ ë°±ì—…"
echo "â”‚   â””â”€â”€ integrate_shapellm_fixed.py  # ðŸ†• ìˆ˜ì •ëœ ë²„ì „"
echo "â”œâ”€â”€ tests/"
echo "â”‚   â””â”€â”€ test_integration.py         # ðŸ†• í†µí•© í…ŒìŠ¤íŠ¸"
echo "â””â”€â”€ scripts/"
echo "    â””â”€â”€ run_tests.py                # ðŸ†• í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸°"
echo ""
echo "ðŸŽ¯ Next actions:"
echo "1. Run tests: python scripts/run_tests.py"
echo "2. If tests pass, replace original file:"
echo "   mv src/integrate_shapellm_fixed.py src/integrate_shapellm.py"
echo "3. Continue with Stage A training preparation"
echo ""
echo "Ready to test the fixed integration!"